# 최적 파라미터로 모델 학습
bestModel <- svm(Violator ~ ., data = pv_train, kernel = "radial",
cost = svmRBF$best.parameters$cost,
gamma = svmRBF$best.parameters$gamma)
rm(list = ls())
# 필요한 패키지 로드
library(mice)      # 결측치 처리를 위한 패키지
library(ggplot2)   # 시각화를 위한 패키지
library(caret)     # 모델링을 위한 패키지
library(visdat)
library(corrplot)
# 필요한 패키지 로드
library(mice)      # 결측치 처리를 위한 패키지
library(ggplot2)   # 시각화를 위한 패키지
library(caret)     # 모델링을 위한 패키지
library(visdat)
# 데이터 로드
pv <- read.csv("parole_violator.csv", fileEncoding = 'UTF-8')
# 데이터 구조 확인
str(pv)
# 결측치 확인
summary(pv)
vis_miss(pv)
# 결측치 처리
set.seed(123) # 재현 가능성을 위해 시드 설정
completed_data <- complete(mice(pv))
completed_data
# 'Violator' 변수의 빈도수를 바 차트로 시각화
ggplot(completed_data, aes(x = Violator)) +
geom_bar(fill = "green", color = "black") +
theme_minimal() +
ggtitle("Bar Chart of Violator Status")
# 'Age'와 'TimeServed' 간의 관계를 산점도로 시각화
ggplot(completed_data, aes(x = Age, y = TimeServed)) +
geom_point(alpha = 0.6, color = "red") +
theme_minimal() +
ggtitle("Scatter Plot of Age vs. Time Served")
# 필요한 패키지 로드
library(caret)
library(pROC)
library(vip)
library(ggplot2)
# 데이터셋을 훈련 세트와 테스트 세트로 분할
set.seed(123)
trainIndex <- createDataPartition(completed_data$Violator, p=.7, list=FALSE)
pv_train <- completed_data[trainIndex,]
pv_test <- completed_data[-trainIndex,]
# 로지스틱 회귀 모델 구축
model <- glm(Violator ~ ., data = pv_train, family = "binomial")
summary(model)
vip(model)
coef(model)
new_data <- data.frame(Male=1, RaceWhite=1, Age=40, State="Kentucky", TimeServed=4, MaxSentence=12, MultipleOffenses=1, Crime="Drugs")
predicted_prob <- predict(model, newdata=new_data, type="response")
print(predicted_prob)
new_data <- data.frame(Male=1, RaceWhite=1, Age=40, State="Kentucky", TimeServed=4, MaxSentence=12, MultipleOffenses=1, Crime="Drugs")
predicted_prob <- predict(model, newdata=new_data)
print(predicted_prob)
# 모델에서 예측 확률 계산
predictions <- predict(model, pv_train)
# 다양한 임계값 설정
thresholds <- seq(0.1, 0.9, by = 0.1)
# 성능 지표 저장을 위한 데이터 프레임 초기화
performance_metrics <- data.frame(Threshold = thresholds,
Accuracy = rep(0, length(thresholds)),
Sensitivity = rep(0, length(thresholds)),
Specificity = rep(0, length(thresholds)))
set.seed(123)
# 각 임계값에 대해 성능 지표 계산
for (t in thresholds) {
# 임계값에 따라 예측 클래스 결정
predicted_classes <- ifelse(predictions > t, 1, 0)
# 혼동 행렬 생성
cm <- confusionMatrix(as.factor(predicted_classes), as.factor(pv_train$Violator))
# 성능 지표 저장
performance_metrics$Accuracy[performance_metrics$Threshold == t] <- cm$overall['Accuracy']
performance_metrics$Sensitivity[performance_metrics$Threshold == t] <- cm$byClass['Sensitivity']
performance_metrics$Specificity[performance_metrics$Threshold == t] <- cm$byClass['Specificity']
}
# 성능 지표에 따른 그래프 그리기
ggplot(performance_metrics, aes(x = Threshold)) +
geom_line(aes(y = Accuracy, colour = "Accuracy")) +
geom_line(aes(y = Sensitivity, colour = "Sensitivity")) +
geom_line(aes(y = Specificity, colour = "Specificity")) +
labs(title = "Threshold에 따른 모델 성능", x = "Threshold", y = "Performance Metric") +
scale_colour_manual(name = "Metrics", values = c(Accuracy = "blue", Sensitivity = "red", Specificity = "green")) +
theme_minimal()
# 데이터셋을 훈련 세트와 테스트 세트로 분할
set.seed(123)
trainIndex <- createDataPartition(completed_data$Violator, p=.7, list=FALSE)
pv_train <- completed_data[trainIndex,]
pv_test <- completed_data[-trainIndex,]
# 로지스틱 회귀 모델 구축
model <- glm(Violator ~ ., data = pv_train, family = "binomial")
summary(model)
vip(model)
coef(model)
new_data <- data.frame(Male=1, RaceWhite=1, Age=40, State="Kentucky", TimeServed=4, MaxSentence=12, MultipleOffenses=1, Crime="Drugs")
predicted_prob <- predict(model, newdata=new_data)
print(predicted_prob)
new_data <- data.frame(Male=1, RaceWhite=1, Age=40, State="Kentucky", TimeServed=4, MaxSentence=12, MultipleOffenses=1, Crime="Drugs")
predicted_prob <- predict(model, newdata=new_data, type="response")
print(predicted_prob)
# 모델에서 예측 확률 계산
predictions <- predict(model, pv_train)
# 다양한 임계값 설정
thresholds <- seq(0.1, 0.9, by = 0.1)
# 성능 지표 저장을 위한 데이터 프레임 초기화
performance_metrics <- data.frame(Threshold = thresholds,
Accuracy = rep(0, length(thresholds)),
Sensitivity = rep(0, length(thresholds)),
Specificity = rep(0, length(thresholds)))
set.seed(123)
# 각 임계값에 대해 성능 지표 계산
for (t in thresholds) {
# 임계값에 따라 예측 클래스 결정
predicted_classes <- ifelse(predictions > t, 1, 0)
# 혼동 행렬 생성
cm <- confusionMatrix(as.factor(predicted_classes), as.factor(pv_train$Violator))
# 성능 지표 저장
performance_metrics$Accuracy[performance_metrics$Threshold == t] <- cm$overall['Accuracy']
performance_metrics$Sensitivity[performance_metrics$Threshold == t] <- cm$byClass['Sensitivity']
performance_metrics$Specificity[performance_metrics$Threshold == t] <- cm$byClass['Specificity']
}
# 성능 지표에 따른 그래프 그리기
ggplot(performance_metrics, aes(x = Threshold)) +
geom_line(aes(y = Accuracy, colour = "Accuracy")) +
geom_line(aes(y = Sensitivity, colour = "Sensitivity")) +
geom_line(aes(y = Specificity, colour = "Specificity")) +
labs(title = "Threshold에 따른 모델 성능", x = "Threshold", y = "Performance Metric") +
scale_colour_manual(name = "Metrics", values = c(Accuracy = "blue", Sensitivity = "red", Specificity = "green")) +
theme_minimal()
# 모델에서 예측 확률 계산
predictions <- predict(model, pv_train, type="response")
# 다양한 임계값 설정
thresholds <- seq(0.1, 0.9, by = 0.1)
# 성능 지표 저장을 위한 데이터 프레임 초기화
performance_metrics <- data.frame(Threshold = thresholds,
Accuracy = rep(0, length(thresholds)),
Sensitivity = rep(0, length(thresholds)),
Specificity = rep(0, length(thresholds)))
set.seed(123)
# 각 임계값에 대해 성능 지표 계산
for (t in thresholds) {
# 임계값에 따라 예측 클래스 결정
predicted_classes <- ifelse(predictions > t, 1, 0)
# 혼동 행렬 생성
cm <- confusionMatrix(as.factor(predicted_classes), as.factor(pv_train$Violator))
# 성능 지표 저장
performance_metrics$Accuracy[performance_metrics$Threshold == t] <- cm$overall['Accuracy']
performance_metrics$Sensitivity[performance_metrics$Threshold == t] <- cm$byClass['Sensitivity']
performance_metrics$Specificity[performance_metrics$Threshold == t] <- cm$byClass['Specificity']
}
# 성능 지표에 따른 그래프 그리기
ggplot(performance_metrics, aes(x = Threshold)) +
geom_line(aes(y = Accuracy, colour = "Accuracy")) +
geom_line(aes(y = Sensitivity, colour = "Sensitivity")) +
geom_line(aes(y = Specificity, colour = "Specificity")) +
labs(title = "Threshold에 따른 모델 성능", x = "Threshold", y = "Performance Metric") +
scale_colour_manual(name = "Metrics", values = c(Accuracy = "blue", Sensitivity = "red", Specificity = "green")) +
theme_minimal()
# 모델에서 예측 확률 계산
predictions <- predict(model, pv_train, type="response")
# 다양한 임계값 설정
thresholds <- seq(0.1, 0.9, by = 0.1)
# F1 Score 저장을 위한 데이터 프레임 초기화
f1_scores <- data.frame(Threshold = thresholds, F1_Score = rep(0, length(thresholds)))
# 각 임계값에 대해 F1 Score 계산
for (t in thresholds) {
predicted_classes <- ifelse(predictions > t, 1, 0)
cm <- confusionMatrix(as.factor(predicted_classes), as.factor(pv_train$Violator), mode = "everything")
f1_scores$F1_Score[f1_scores$Threshold == t] <- cm$byClass['F1']
}
# F1 Score에 따른 그래프 그리기
ggplot(f1_scores, aes(x = Threshold, y = F1_Score)) +
geom_line(color = "blue") +
labs(title = "Threshold에 따른 F1 Score", x = "Threshold", y = "F1 Score") +
theme_minimal()
# 필요한 라이브러리 불러오기
library(caret)
library(glmnet)
library(pROC)
# 기존 로지스틱 회귀 모델을 Lasso 정규화로 확장
set.seed(123)
model_lasso <- cv.glmnet(
as.matrix(pv_train[-ncol(pv_train)]),  # 입력 변수만 사용
pv_train$Violator,                  # 종속 변수 지정
family = "binomial",             # 이진 분류를 위한 binomial 옵션
alpha = 1,                       # Lasso 정규화 적용 (alpha = 1)
type.measure = "deviance",       # 성능 측정으로 deviance 사용
nfolds = 10                      # 10-fold 교차 검증
)
# 최적의 람다 선택
best_lambda <- model_lasso$lambda.min
cat("Best Lambda:", best_lambda, "\n")
# 최적의 람다 값에서 모든 계수를 확인
coef_lasso <- coef(model_lasso, s = "lambda.min")
coef_lasso_full <- as.matrix(coef_lasso)  # Sparse matrix를 full matrix로 변환
# 모든 계수 출력
print(coef_lasso_full)
# 예측 확률 계산
train_logit_probs <- predict(model, train)
# 예측 확률 계산
train_logit_probs <- predict(model, pv_train, type="response")
test_logit_probs <- predict(model, pv_test, type="response")
train_lasso_probs <- predict(model_lasso, newx = as.matrix(train[-ncol(train)]), s = "lambda.min")
# 최적의 람다 선택
best_lambda <- model_lasso$lambda.min
cat("Best Lambda:", best_lambda, "\n")
# 최적의 람다 값에서 모든 계수를 확인
coef_lasso <- coef(model_lasso, s = "lambda.min")
coef_lasso_full <- as.matrix(coef_lasso)  # Sparse matrix를 full matrix로 변환
# 모든 계수 출력
print(coef_lasso_full)
# 예측 확률 계산
train_logit_probs <- predict(model, pv_train, type="response")
test_logit_probs <- predict(model, pv_test, type="response")
train_lasso_probs <- predict(model_lasso, newx = as.matrix(train[-ncol(train)]), s = "lambda.min")
# 로지스틱 회귀 모델 구축
model <- glm(Violator ~ ., data = pv_train, family = "binomial")
summary(model)
vip(model)
coef(model)
# 레벨 동기화
pv_train$Violator <- factor(pv_train$Violator)
pv_test$Violator <- factor(pv_test$Violator, levels = levels(pv_train$Violator))
# 최적 파라미터로 모델 학습
bestModel <- svm(Violator ~ ., data = pv_train, kernel = "radial",
cost = svmRBF$best.parameters$cost,
gamma = svmRBF$best.parameters$gamma)
# 예측 확률 계산
train_logit_probs <- predict(model, pv_train, type="response")
test_logit_probs <- predict(model, pv_test, type="response")
train_lasso_probs <- predict(model_lasso, newx = as.matrix(train[-ncol(train)]), s = "lambda.min")
# 예측 확률 계산
train_logit_probs <- predict(model, pv_train, type="response")
test_logit_probs <- predict(model, pv_test, type="response")
train_lasso_probs <- predict(model_lasso, newx = as.matrix(pv_train[-ncol(pv_train)]), s = "lambda.min")
test_lasso_probs <- predict(model_lasso, newx = as.matrix(Pv_test[-ncol(pv_test)]), s = "lambda.min")
# 예측 확률 계산
train_logit_probs <- predict(model, pv_train, type="response")
test_logit_probs <- predict(model, pv_test, type="response")
train_lasso_probs <- predict(model_lasso, newx = as.matrix(pv_train[-ncol(pv_train)]), s = "lambda.min")
test_lasso_probs <- predict(model_lasso, newx = as.matrix(pv_test[-ncol(pv_test)]), s = "lambda.min")
# 훈련 세트와 테스트 세트의 ROC 곡선 및 AUC 계산
train_logit_roc <- roc(train$Violator, train_logit_probs)
# 예측 확률 계산
train_logit_probs <- predict(model, pv_train, type="response")
test_logit_probs <- predict(model, pv_test, type="response")
train_lasso_probs <- predict(model_lasso, newx = as.matrix(pv_train[-ncol(pv_train)]), s = "lambda.min")
test_lasso_probs <- predict(model_lasso, newx = as.matrix(pv_test[-ncol(pv_test)]), s = "lambda.min")
# 훈련 세트와 테스트 세트의 ROC 곡선 및 AUC 계산
train_logit_roc <- roc(pv_train$Violator, train_logit_probs)
train_lasso_roc <- roc(pv_train$Violator, train_lasso_probs)
test_logit_roc <- roc(pv_test$Violator, test_logit_probs)
test_lasso_roc <- roc(pv_test$Violator, test_lasso_probs)
# ROC 곡선 시각화
plot(train_logit_roc, col = "blue", main = "ROC Curves - Training and Test Sets")
plot(train_lasso_roc, col = "red", add = TRUE)
plot(test_logit_roc, col = "green", add = TRUE)
plot(test_lasso_roc, col = "orange", add = TRUE)
legend("bottomright", legend = c("Train Logistic", "Train Lasso", "Test Logistic", "Test Lasso"), col = c("blue", "red", "green", "orange"), lwd = 2)
# AUC 값 출력
cat("AUC for Training Set - Logistic Regression:", auc(train_logit_roc), "\n")
cat("AUC for Training Set - Lasso:", auc(train_lasso_roc), "\n")
cat("AUC for Test Set - Logistic Regression:", auc(test_logit_roc), "\n")
cat("AUC for Test Set - Lasso:", auc(test_lasso_roc), "\n")
# 레벨 동기화
pv_train$Violator <- factor(pv_train$Violator)
pv_test$Violator <- factor(pv_test$Violator, levels = levels(pv_train$Violator))
# 최적 파라미터로 모델 학습
bestModel <- svm(Violator ~ ., data = pv_train, kernel = "radial",
cost = svmRBF$best.parameters$cost,
gamma = svmRBF$best.parameters$gamma)
# 필요한 라이브러리 불러오기
library(caret)
library(e1071)
library(pROC)
# 레벨 동기화
pv_train$Violator <- factor(pv_train$Violator)
pv_test$Violator <- factor(pv_test$Violator, levels = levels(pv_train$Violator))
# 최적 파라미터로 모델 학습
bestModel <- svm(Violator ~ ., data = pv_train, kernel = "radial",
cost = svmRBF$best.parameters$cost,
gamma = svmRBF$best.parameters$gamma)
#RBF 컨널 svm
set.seed(123)
svmRBF <-tune(svm, Violator ~ ., data = pv_train, kernel = "radial",
ranges = list(cost = c(0.01, 0.1, 1, 10, 100, 1000),
gamma = c(0.01, 0.1, 1, 10, 100))
)
summary(svmRBF)
# 레벨 동기화
pv_train$Violator <- factor(pv_train$Violator)
pv_test$Violator <- factor(pv_test$Violator, levels = levels(pv_train$Violator))
# 최적 파라미터로 모델 학습
bestModel <- svm(Violator ~ ., data = pv_train, kernel = "radial",
cost = svmRBF$best.parameters$cost,
gamma = svmRBF$best.parameters$gamma)
# 성능 평가
predictions_train <- predict(bestModel,  pv_train, type="response")
predictions_test <- predict(bestModel,  pv_test, type="response")
predictions_train <- factor(predictions_train, levels = levels(pv_train$Violator))
predictions_test <- factor(predictions_test, levels = levels(pv_test$Violator))
confMatrix_train <- confusionMatrix(predictions_train, pv_train$Violator)
confMatrix_test <- confusionMatrix(predictions_test, pv_test$Violator)
# 결과 출력
print(confMatrix_train)
print(confMatrix_test)
rm(list =ls())
# 필요한 패키지 로드
library(mice)      # 결측치 처리를 위한 패키지
library(ggplot2)   # 시각화를 위한 패키지
library(caret)     # 모델링을 위한 패키지
library(visdat)
# 데이터 로드
pv <- read.csv("parole_violator.csv", fileEncoding = 'UTF-8')
# 데이터 구조 확인
str(pv)
# 결측치 확인
summary(pv)
vis_miss(pv)
# 결측치 처리
set.seed(123) # 재현 가능성을 위해 시드 설정
completed_data <- complete(mice(pv))
completed_data
# 'Violator' 변수의 빈도수를 바 차트로 시각화
ggplot(completed_data, aes(x = Violator)) +
geom_bar(fill = "green", color = "black") +
theme_minimal() +
ggtitle("Bar Chart of Violator Status")
# 'Age'와 'TimeServed' 간의 관계를 산점도로 시각화
ggplot(completed_data, aes(x = Age, y = TimeServed)) +
geom_point(alpha = 0.6, color = "red") +
theme_minimal() +
ggtitle("Scatter Plot of Age vs. Time Served")
# 필요한 패키지 로드
library(caret)
library(pROC)
library(vip)
library(ggplot2)
# 데이터셋을 훈련 세트와 테스트 세트로 분할
set.seed(123)
trainIndex <- createDataPartition(completed_data$Violator, p=.7, list=FALSE)
pv_train <- completed_data[trainIndex,]
pv_test <- completed_data[-trainIndex,]
# 로지스틱 회귀 모델 구축
model <- glm(Violator ~ ., data = pv_train, family = "binomial")
summary(model)
vip(model)
coef(model)
new_data <- data.frame(Male=1, RaceWhite=1, Age=40, State="Kentucky", TimeServed=4, MaxSentence=12, MultipleOffenses=1, Crime="Drugs")
predicted_prob <- predict(model, newdata=new_data, type="response")
print(predicted_prob)
# 모델에서 예측 확률 계산
predictions <- predict(model, pv_train, type="response")
# 다양한 임계값 설정
thresholds <- seq(0.1, 0.9, by = 0.1)
# 성능 지표 저장을 위한 데이터 프레임 초기화
performance_metrics <- data.frame(Threshold = thresholds,
Accuracy = rep(0, length(thresholds)),
Sensitivity = rep(0, length(thresholds)),
Specificity = rep(0, length(thresholds)))
set.seed(123)
# 각 임계값에 대해 성능 지표 계산
for (t in thresholds) {
# 임계값에 따라 예측 클래스 결정
predicted_classes <- ifelse(predictions > t, 1, 0)
# 혼동 행렬 생성
cm <- confusionMatrix(as.factor(predicted_classes), as.factor(pv_train$Violator))
# 성능 지표 저장
performance_metrics$Accuracy[performance_metrics$Threshold == t] <- cm$overall['Accuracy']
performance_metrics$Sensitivity[performance_metrics$Threshold == t] <- cm$byClass['Sensitivity']
performance_metrics$Specificity[performance_metrics$Threshold == t] <- cm$byClass['Specificity']
}
# 성능 지표에 따른 그래프 그리기
ggplot(performance_metrics, aes(x = Threshold)) +
geom_line(aes(y = Accuracy, colour = "Accuracy")) +
geom_line(aes(y = Sensitivity, colour = "Sensitivity")) +
geom_line(aes(y = Specificity, colour = "Specificity")) +
labs(title = "Threshold에 따른 모델 성능", x = "Threshold", y = "Performance Metric") +
scale_colour_manual(name = "Metrics", values = c(Accuracy = "blue", Sensitivity = "red", Specificity = "green")) +
theme_minimal()
# 모델에서 예측 확률 계산
predictions <- predict(model, pv_train, type="response")
# 다양한 임계값 설정
thresholds <- seq(0.1, 0.9, by = 0.1)
# F1 Score 저장을 위한 데이터 프레임 초기화
f1_scores <- data.frame(Threshold = thresholds, F1_Score = rep(0, length(thresholds)))
# 각 임계값에 대해 F1 Score 계산
for (t in thresholds) {
predicted_classes <- ifelse(predictions > t, 1, 0)
cm <- confusionMatrix(as.factor(predicted_classes), as.factor(pv_train$Violator), mode = "everything")
f1_scores$F1_Score[f1_scores$Threshold == t] <- cm$byClass['F1']
}
# F1 Score에 따른 그래프 그리기
ggplot(f1_scores, aes(x = Threshold, y = F1_Score)) +
geom_line(color = "blue") +
labs(title = "Threshold에 따른 F1 Score", x = "Threshold", y = "F1 Score") +
theme_minimal()
# 필요한 라이브러리 불러오기
library(caret)
library(glmnet)
library(pROC)
# 기존 로지스틱 회귀 모델을 Lasso 정규화로 확장
set.seed(123)
model_lasso <- cv.glmnet(
as.matrix(pv_train[-ncol(pv_train)]),  # 입력 변수만 사용
pv_train$Violator,                  # 종속 변수 지정
family = "binomial",             # 이진 분류를 위한 binomial 옵션
alpha = 1,                       # Lasso 정규화 적용 (alpha = 1)
type.measure = "deviance",       # 성능 측정으로 deviance 사용
nfolds = 10                      # 10-fold 교차 검증
)
# 최적의 람다 선택
best_lambda <- model_lasso$lambda.min
cat("Best Lambda:", best_lambda, "\n")
# 최적의 람다 값에서 모든 계수를 확인
coef_lasso <- coef(model_lasso, s = "lambda.min")
coef_lasso_full <- as.matrix(coef_lasso)  # Sparse matrix를 full matrix로 변환
# 모든 계수 출력
print(coef_lasso_full)
# 예측 확률 계산
train_logit_probs <- predict(model, pv_train, type="response")
test_logit_probs <- predict(model, pv_test, type="response")
train_lasso_probs <- predict(model_lasso, newx = as.matrix(pv_train[-ncol(pv_train)]), s = "lambda.min")
test_lasso_probs <- predict(model_lasso, newx = as.matrix(pv_test[-ncol(pv_test)]), s = "lambda.min")
# 훈련 세트와 테스트 세트의 ROC 곡선 및 AUC 계산
train_logit_roc <- roc(pv_train$Violator, train_logit_probs)
train_lasso_roc <- roc(pv_train$Violator, train_lasso_probs)
test_logit_roc <- roc(pv_test$Violator, test_logit_probs)
test_lasso_roc <- roc(pv_test$Violator, test_lasso_probs)
# ROC 곡선 시각화
plot(train_logit_roc, col = "blue", main = "ROC Curves - Training and Test Sets")
plot(train_lasso_roc, col = "red", add = TRUE)
plot(test_logit_roc, col = "green", add = TRUE)
plot(test_lasso_roc, col = "orange", add = TRUE)
legend("bottomright", legend = c("Train Logistic", "Train Lasso", "Test Logistic", "Test Lasso"), col = c("blue", "red", "green", "orange"), lwd = 2)
# AUC 값 출력
cat("AUC for Training Set - Logistic Regression:", auc(train_logit_roc), "\n")
cat("AUC for Training Set - Lasso:", auc(train_lasso_roc), "\n")
cat("AUC for Test Set - Logistic Regression:", auc(test_logit_roc), "\n")
cat("AUC for Test Set - Lasso:", auc(test_lasso_roc), "\n")
# 필요한 라이브러리 불러오기
library(caret)
library(e1071)
library(pROC)
#선형 svm
set.seed(123)
svmLine <- tune(svm, Violator ~ ., data = pv_train, kernel = "linear",
ranges = list(cost = 10^(-2:2))
)
summary(svmLine)
#RBF 컨널 svm
set.seed(123)
svmRBF <-tune(svm, Violator ~ ., data = pv_train, kernel = "radial",
ranges = list(cost = c(0.01, 0.1, 1, 10, 100, 1000),
gamma = c(0.01, 0.1, 1, 10, 100))
)
summary(svmRBF)
#다항식 svm
set.seed(123)
svmPolyn <- tune(svm, Violator ~ ., data = pv_train, kernel = "polynomial",
ranges = list(cost = c(0.1, 1, 10, 100, 1000),
degree =c(2, 3, 4))
)
summary(svmPolyn)
# 레벨 동기화
pv_train$Violator <- factor(pv_train$Violator)
pv_test$Violator <- factor(pv_test$Violator, levels = levels(pv_train$Violator))
# 최적 파라미터로 모델 학습
bestModel <- svm(Violator ~ ., data = pv_train, kernel = "radial",
cost = svmRBF$best.parameters$cost,
gamma = svmRBF$best.parameters$gamma)
# 성능 평가
predictions_train <- predict(bestModel,  pv_train, type="response")
predictions_test <- predict(bestModel,  pv_test, type="response")
predictions_train <- factor(predictions_train, levels = levels(pv_train$Violator))
predictions_test <- factor(predictions_test, levels = levels(pv_test$Violator))
confMatrix_train <- confusionMatrix(predictions_train, pv_train$Violator)
confMatrix_test <- confusionMatrix(predictions_test, pv_test$Violator)
# 결과 출력
print(confMatrix_train)
print(confMatrix_test)
# 훈련 세트에서의 ROC 곡선 및 AUC 계산
roc_train <- roc(response = pv_train$Violator, predictor = as.numeric(predictions_train))
auc_train <- auc(roc_train)
# 테스트 세트에서의 ROC 곡선 및 AUC 계산
roc_test <- roc(response = pv_test$Violator, predictor = as.numeric(predictions_test))
auc_test <- auc(roc_test)
# 결과 출력
print(paste("AUC for Training Set:", auc_train))
print(paste("AUC for Testing Set:", auc_test))
# 레벨 동기화
pv_train$Violator <- factor(pv_train$Violator)
pv_test$Violator <- factor(pv_test$Violator, levels = levels(pv_train$Violator))
# 최적 파라미터로 모델 학습
bestModel <- svm(Violator ~ ., data = pv_train, kernel = "radial",
cost = svmRBF$best.parameters$cost,
gamma = svmRBF$best.parameters$gamma)
# 성능 평가
predictions_train <- predict(bestModel,  pv_train)
predictions_test <- predict(bestModel,  pv_test)
predictions_train <- factor(predictions_train, levels = levels(pv_train$Violator))
predictions_test <- factor(predictions_test, levels = levels(pv_test$Violator))
confMatrix_train <- confusionMatrix(predictions_train, pv_train$Violator)
confMatrix_test <- confusionMatrix(predictions_test, pv_test$Violator)
# 결과 출력
print(confMatrix_train)
print(confMatrix_test)
# 결측치 확인
vis_miss(pv)
