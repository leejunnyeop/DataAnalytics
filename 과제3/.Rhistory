# 예측 오차 계산
train_rmse <- sqrt(mean((train_predictions - trainSet$신입생경쟁률)^2))
test_rmse <- sqrt(mean((test_predictions - testSet$신입생경쟁률)^2))
# 결과를 데이터 프레임으로 저장 및 출력
results <- data.frame(
Train_RMSE = train_rmse,
Test_RMSE = test_rmse
)
print(results)
library(leaps)
library(Metrics) # RMSE 함수를 위한 패키지
# 결과를 저장할 빈 데이터 프레임을 준비합니다.
results_t <- data.frame()
# nvmax 값이 데이터셋의 변수 수를 초과하지 않도록 합니다.
max_vars <- ncol(x_trainSet)
# nvmax 값을 변경하면서 모델 생성 및 검증 반복
for (nv in 1:max_vars) {
# regsubsets 모델 생성
bwd_model_t <- regsubsets(x =신입생경쟁률~., data = data_final,  nvmax = nv, method = "backward")
# 각 모델에서 선택된 변수들을 얻습니다.
model_info <- summary(bwd_model_t)
# nvmax에 맞는 모델을 얻습니다. nv가 선택된 변수의 개수가 됩니다.
selected_vars <- names(which(model_info$which[nv,]))
# Intercept가 포함되어 있으므로 이를 제외합니다.
selected_vars <- selected_vars[selected_vars != "(Intercept)"]
# Intercept를 제외한 변수명으로 수식 생성
reduced_formula <- as.formula(paste("신입생경쟁률 ~", paste(selected_vars, collapse = " + ")))
# 최종 모델 생성
final_model_bwd_t <- lm(reduced_formula, data = trainSet)
# training set과 test set에 대한 예측
train_predictions_t <- predict(final_model_bwd_t, newdata = trainSet)
test_predictions_t <- predict(final_model_bwd_t, newdata = testSet)
# 예측 오차 계산
train_rmse_t <- RMSE(train_predictions_t, trainSet$신입생경쟁률)
test_rmse_t <-  RMSE(test_predictions_t, testSet$신입생경쟁률)
# 결과를 데이터 프레임에 추가
results_t <- rbind(results, data.frame(
nvmax = nv,
Train_RMSE = train_rmse_t,
Test_RMSE = test_rmse_t
))
}
library(leaps)
library(Metrics) # RMSE 함수를 위한 패키지
# 결과를 저장할 빈 데이터 프레임을 준비합니다.
results_t <- data.frame()
# nvmax 값이 데이터셋의 변수 수를 초과하지 않도록 합니다.
max_vars <- ncol(x_trainSet)
# nvmax 값을 변경하면서 모델 생성 및 검증 반복
for (nv in 1:max_vars) {
# regsubsets 모델 생성
bwd_model_t <- regsubsets(x =신입생경쟁률~., data = trainSet,  nvmax = nv, method = "backward")
# 각 모델에서 선택된 변수들을 얻습니다.
model_info <- summary(bwd_model_t)
# nvmax에 맞는 모델을 얻습니다. nv가 선택된 변수의 개수가 됩니다.
selected_vars <- names(which(model_info$which[nv,]))
# Intercept가 포함되어 있으므로 이를 제외합니다.
selected_vars <- selected_vars[selected_vars != "(Intercept)"]
# Intercept를 제외한 변수명으로 수식 생성
reduced_formula <- as.formula(paste("신입생경쟁률 ~", paste(selected_vars, collapse = " + ")))
# 최종 모델 생성
final_model_bwd_t <- lm(reduced_formula, data = trainSet)
# training set과 test set에 대한 예측
train_predictions_t <- predict(final_model_bwd_t, newdata = trainSet)
test_predictions_t <- predict(final_model_bwd_t, newdata = testSet)
# 예측 오차 계산
train_rmse_t <- RMSE(train_predictions_t, trainSet$신입생경쟁률)
test_rmse_t <-  RMSE(test_predictions_t, testSet$신입생경쟁률)
# 결과를 데이터 프레임에 추가
results_t <- rbind(results, data.frame(
nvmax = nv,
Train_RMSE = train_rmse_t,
Test_RMSE = test_rmse_t
))
}
library(glmnet)
library(caret)
library(glmnet)
library(caret)
set.seed(123)
# 모델 매트릭스 생성
x_train <- model.matrix(신입생경쟁률~., trainSet)[,-1]
y_train <- trainSet$신입생경쟁률
x_test <- model.matrix(신입생경쟁률~., testSet)[,-1]
y_test <- testSet$신입생경쟁률
# Ridge 회귀
ridge_cv <- cv.glmnet(x_train, y_train, alpha = 0, nfolds = 10)
best_lambda_ridge <- ridge_cv$lambda.min
# Lasso 회귀
lasso_cv <- cv.glmnet(x_train, y_train, alpha = 1, nfolds = 10)
best_lambda_lasso <- lasso_cv$lambda.min
set.seed(123)
# Ridge 예측 및 RMSE 계산
ridge_pred <- predict(ridge_cv, s = best_lambda_ridge, newx = x_train)
ridge_pred_test <- predict(ridge_cv, s = best_lambda_ridge, newx = x_test)
ridge_rmse <- RMSE(ridge_pred, trainSet$신입생경쟁률 )
ridge_rmse_test <- RMSE(ridge_pred_test, testSet$신입생경쟁률)
# Lasso 예측 및 RMSE 계산
lasso_pred <- predict(lasso_cv, s = best_lambda_lasso, newx = x_train)
lasso_pred_test <- predict(lasso_cv, s = best_lambda_lasso, newx = x_test)
lasso_rmse <- RMSE(lasso_pred, trainSet$신입생경쟁률)
lasso_rmse_test <- RMSE(lasso_pred_test, testSet$신입생경쟁률)
print(paste("Ridge RMSE train:", ridge_rmse))
print(paste("Lasso RMSE train:", lasso_rmse))
print(paste("Ridge RMSE test:", ridge_rmse))
print(paste("Lasso RMSE test:", lasso_rmse))
print(paste("Ridge 람다:", best_lambda_lasso))
print(paste("Lasso 람다:", best_lambda_ridge))
ridge_cv
lasso_cv
library(car)
library(pls)
reg_pcr <- lm(신입생경쟁률~ ., data = trainSet)
vif(reg_pcr)
library(car)
library(pls)
library(car)
library(pls)
library(vip)
reg_pcr <- lm(신입생경쟁률~ ., data = trainSet)
vif(reg_pcr)
library(car)
library(pls)
library(vif)
library(car)
library(pls)
reg_pcr <- lm(신입생경쟁률~ ., data = trainSet)
vif(reg_pcr)
reg_pcr_t <- lm(신입생경쟁률~ ., data = trainSet)
vif(reg_pcr_t)
# 초기세팅
library(caret)
setwd("C:/Users/ktnu2/데이터애널리스트/과제3")
data <- read.csv("kor_univ_stat.csv", fileEncoding = "euc-kr")
data <- na.omit(data)   # 결측지 포함한 행 제거
data <- subset(data, data$재학생 >= 100)  # 재학생 100 미만인 대학의 데이터 제거
data <- data[, !(names(data) %in% c("학교명", "신입생충원율"))] # "학교명" 과 신입생 충원율"은 feature에서 제외외
head(data)
# 범주형 변수 factor로 변환
data$년도 <- as.factor(data$년도)
data$설립유형 <- as.factor(data$설립유형)
data$지역명 <- as.factor(data$지역명)
year_dummies <- model.matrix(~년도 -1, data = data)
type_dummies <- model.matrix(~설립유형-1, data = data)
region_dummies <- model.matrix(~지역명 -1, data = data)
data_onhot <- cbind(year_dummies, type_dummies, region_dummies)
# Min-Max 데이터 스케일링
preProValue <- preProcess(data[, sapply(data, is.numeric)], method = "range")
data_scaled <- predict(preProValue, data[, sapply(data, is.numeric)])
# 데이터 합치기기
data_final <- cbind(data_onhot, data_scaled)
# 결과 확인인
head(data_final)
library(ggplot2)
library(corrplot)
library(corrplot)
# 연속형 변수만을 포함하는 상관관계 행렬 계산
continuous_vars <- data[, sapply(data, is.numeric)]  # 연속형 변수만 선택
cor_matrix <- cor(continuous_vars, use = "complete.obs")  # 결측치를 제외하고 상관관계 계산
# 상관관계 행렬 시각화
corrplot(cor_matrix, method = "circle", order = "hclust", tl.cex = 0.5,)  # 상관계수 추가
data_2023 <- data[data$년도 == "2023",]
ggplot(data_2023, aes(x = 지역명, y = 신입생경쟁률 ))+
geom_boxplot() +
labs(title = "2023년 지역별 신입생경쟁률", x= "지역", y = "신입생경쟁률")
set.seed(123)
results <- data.frame()
for (i in 1:5){
set.seed(i * 100)
index <- createDataPartition(data_final$신입생경쟁률, p=0.7, list = FALSE)
trainSet <- data_final[index, ]
testSet <- data_final[-index, ]
lm_model <- lm(신입생경쟁률~. , data = trainSet)
test_predictions <- predict(lm_model, newdata= testSet)
train_predictions <- predict(lm_model, newdata= trainSet)
train_rmse <- RMSE(train_predictions, trainSet$신입생경쟁률)
test_rmse <- RMSE(test_predictions, testSet$신입생경쟁률)
results <- rbind(results, data.frame(Round = i, Train_RMSE = train_rmse, Test_RMSE = test_rmse))
}
print(results)
# RMSE값에 대한 시각화를 별도로 진행합니다
ggplot(results, aes(x = Round)) +
geom_point(aes(y = Train_RMSE, color = "Training Set")) +
geom_line(aes(y = Train_RMSE, color = "Training Set")) +
geom_point(aes(y = Test_RMSE, color = "Test Set")) +
geom_line(aes(y = Test_RMSE, color = "Test Set")) +
scale_color_manual(values = c("Training Set" = "blue", "Test Set" = "red"),
labels = c("Training Set", "Test Set")) +
labs(title = "Round Seed 변동에 따른 Train_RMSE와 Test_RMSE",
x = "Round",
y = "RMSE",
color = "Dataset") +
guides(color = guide_legend(title = "Dataset")) +
theme_minimal()
library(leaps)
# 특성 알아보기
set.seed(123)
reg_full <- regsubsets(신입생경쟁률~. , data = trainSet, nvmax = NULL)
reg_summary <- summary(reg_full)
max(reg_summary$adjr2)
which.max(reg_summary$adjr2)
# 특성 알아보기
coef <- coef(reg_full, 19)
coef
train_control <- trainControl(method = "repeatedcv", number = 5, repeats = 10)
set.seed(123)
fwd_model <- train(신입생경쟁률~., data = trainSet, method = "leapForward", tuneGrid = data.frame(nvmax = 1: 20), trControl = train_control)
fwd_model
fwd_model$bestTune
ggplot(fwd_model$results, aes(x= nvmax, y=RMSE))+
geom_point()+
geom_line()+
theme_bw()
coef_fwd_cv <- coef(fwd_model$finalModel, fwd_model$bestTune$nvmax)
coef_fwd_cv
set.seed(123)
bwd_model <- train(신입생경쟁률~., data = trainSet, method = "leapBackward", tuneGrid = data.frame(nvmax = 1: 20), trControl = train_control)
bwd_model
bwd_model$bestTune
ggplot(bwd_model$results, aes(x= nvmax, y=RMSE))+
geom_point()+
geom_line()+
theme_bw()
coef_bwd_cv <- coef(bwd_model$finalModel, bwd_model$bestTune$nvmax)
coef_bwd_cv
# 선택된 변수 확인
selected_vars <- names(coef(bwd_model$finalModel, bwd_model$bestTune$nvmax))
# Intercept를 제외한 변수명으로 수식 생성
reduced_formula <- as.formula(paste("신입생경쟁률 ~", paste(selected_vars[-1], collapse = " + ")))
# 최종 모델 생성
final_model_bwd <- lm(reduced_formula, data = trainSet)
# training set과 test set에 대한 예측
train_predictions <- predict(final_model_bwd, newdata = trainSet)
test_predictions <- predict(final_model_bwd, newdata = testSet)
# 예측 오차 계산
train_rmse <- sqrt(mean((train_predictions - trainSet$신입생경쟁률)^2))
test_rmse <- sqrt(mean((test_predictions - testSet$신입생경쟁률)^2))
# 결과를 데이터 프레임으로 저장 및 출력
results <- data.frame(
Train_RMSE = train_rmse,
Test_RMSE = test_rmse
)
print(results)
library(glmnet)
library(caret)
reg_pcr_t <- lm(신입생경쟁률~ ., data = trainSet)
vif(reg_pcr_t)
reg_pcr_tt <- lm(신입생경쟁률~ ., data = trainSet)
vif(reg_pcr_tt)
# 초기세팅
library(caret)
setwd("C:/Users/ktnu2/데이터애널리스트/과제3")
data <- read.csv("kor_univ_stat.csv", fileEncoding = "euc-kr")
data <- na.omit(data)   # 결측지 포함한 행 제거
data <- subset(data, data$재학생 >= 100)  # 재학생 100 미만인 대학의 데이터 제거
data <- data[, !(names(data) %in% c("학교명", "신입생충원율"))] # "학교명" 과 신입생 충원율"은 feature에서 제외외
head(data)
reg_pcr_tt <- lm(신입생경쟁률~ ., data = trainSet)
vif(reg_pcr_tt)
# 초기세팅
library(caret)
setwd("C:/Users/ktnu2/데이터애널리스트/과제3")
data <- read.csv("kor_univ_stat.csv", fileEncoding = "euc-kr")
data <- na.omit(data)   # 결측지 포함한 행 제거
data <- subset(data, data$재학생 >= 100)  # 재학생 100 미만인 대학의 데이터 제거
data <- data[, !(names(data) %in% c("학교명", "신입생충원율"))] # "학교명" 과 신입생 충원율"은 feature에서 제외외
head(data)
# 범주형 변수 factor로 변환
data$년도 <- as.factor(data$년도)
data$설립유형 <- as.factor(data$설립유형)
data$지역명 <- as.factor(data$지역명)
year_dummies <- model.matrix(~년도 -1, data = data)
type_dummies <- model.matrix(~설립유형-1, data = data)
region_dummies <- model.matrix(~지역명 -1, data = data)
data_onhot <- cbind(year_dummies, type_dummies, region_dummies)
# Min-Max 데이터 스케일링
preProValue <- preProcess(data[, sapply(data, is.numeric)], method = "range")
data_scaled <- predict(preProValue, data[, sapply(data, is.numeric)])
# 데이터 합치기기
data_final <- cbind(data_onhot, data_scaled)
# 결과 확인인
head(data_final)
library(ggplot2)
library(corrplot)
library(corrplot)
# 연속형 변수만을 포함하는 상관관계 행렬 계산
continuous_vars <- data[, sapply(data, is.numeric)]  # 연속형 변수만 선택
cor_matrix <- cor(continuous_vars, use = "complete.obs")  # 결측치를 제외하고 상관관계 계산
# 상관관계 행렬 시각화
corrplot(cor_matrix, method = "circle", order = "hclust", tl.cex = 0.5,)  # 상관계수 추가
# 연속형 변수만을 포함하는 상관관계 행렬 계산
continuous_vars <- data[, sapply(data, is.numeric)]  # 연속형 변수만 선택
cor_matrix <- cor(continuous_vars, use = "complete.obs")  # 결측치를 제외하고 상관관계 계산
# 상관관계 행렬 시각화
corrplot::corrplot(cor_matrix, method = "circle", order = "hclust", tl.cex = 0.5,)  # 상관계수 추가
data_2023 <- data[data$년도 == "2023",]
ggplot(data_2023, aes(x = 지역명, y = 신입생경쟁률 ))+
geom_boxplot() +
labs(title = "2023년 지역별 신입생경쟁률", x= "지역", y = "신입생경쟁률")
set.seed(123)
results <- data.frame()
for (i in 1:5){
set.seed(i * 100)
index <- createDataPartition(data_final$신입생경쟁률, p=0.7, list = FALSE)
trainSet <- data_final[index, ]
testSet <- data_final[-index, ]
lm_model <- lm(신입생경쟁률~. , data = trainSet)
test_predictions <- predict(lm_model, newdata= testSet)
train_predictions <- predict(lm_model, newdata= trainSet)
train_rmse <- RMSE(train_predictions, trainSet$신입생경쟁률)
test_rmse <- RMSE(test_predictions, testSet$신입생경쟁률)
results <- rbind(results, data.frame(Round = i, Train_RMSE = train_rmse, Test_RMSE = test_rmse))
}
print(results)
# RMSE값에 대한 시각화를 별도로 진행합니다
ggplot(results, aes(x = Round)) +
geom_point(aes(y = Train_RMSE, color = "Training Set")) +
geom_line(aes(y = Train_RMSE, color = "Training Set")) +
geom_point(aes(y = Test_RMSE, color = "Test Set")) +
geom_line(aes(y = Test_RMSE, color = "Test Set")) +
scale_color_manual(values = c("Training Set" = "blue", "Test Set" = "red"),
labels = c("Training Set", "Test Set")) +
labs(title = "Round Seed 변동에 따른 Train_RMSE와 Test_RMSE",
x = "Round",
y = "RMSE",
color = "Dataset") +
guides(color = guide_legend(title = "Dataset")) +
theme_minimal()
library(leaps)
# 특성 알아보기
set.seed(123)
reg_full <- regsubsets(신입생경쟁률~. , data = trainSet, nvmax = NULL)
reg_summary <- summary(reg_full)
max(reg_summary$adjr2)
which.max(reg_summary$adjr2)
# 특성 알아보기
coef <- coef(reg_full, 19)
coef
train_control <- trainControl(method = "repeatedcv", number = 5, repeats = 10)
set.seed(123)
fwd_model <- train(신입생경쟁률~., data = trainSet, method = "leapForward", tuneGrid = data.frame(nvmax = 1: 20), trControl = train_control)
fwd_model
fwd_model$bestTune
ggplot(fwd_model$results, aes(x= nvmax, y=RMSE))+
geom_point()+
geom_line()+
theme_bw()
coef_fwd_cv <- coef(fwd_model$finalModel, fwd_model$bestTune$nvmax)
coef_fwd_cv
set.seed(123)
bwd_model <- train(신입생경쟁률~., data = trainSet, method = "leapBackward", tuneGrid = data.frame(nvmax = 1: 20), trControl = train_control)
bwd_model
bwd_model$bestTune
ggplot(bwd_model$results, aes(x= nvmax, y=RMSE))+
geom_point()+
geom_line()+
theme_bw()
coef_bwd_cv <- coef(bwd_model$finalModel, bwd_model$bestTune$nvmax)
coef_bwd_cv
# 선택된 변수 확인
selected_vars <- names(coef(bwd_model$finalModel, bwd_model$bestTune$nvmax))
# Intercept를 제외한 변수명으로 수식 생성
reduced_formula <- as.formula(paste("신입생경쟁률 ~", paste(selected_vars[-1], collapse = " + ")))
# 최종 모델 생성
final_model_bwd <- lm(reduced_formula, data = trainSet)
# training set과 test set에 대한 예측
train_predictions <- predict(final_model_bwd, newdata = trainSet)
test_predictions <- predict(final_model_bwd, newdata = testSet)
# 예측 오차 계산
train_rmse <- sqrt(mean((train_predictions - trainSet$신입생경쟁률)^2))
test_rmse <- sqrt(mean((test_predictions - testSet$신입생경쟁률)^2))
# 결과를 데이터 프레임으로 저장 및 출력
results <- data.frame(
Train_RMSE = train_rmse,
Test_RMSE = test_rmse
)
print(results)
library(glmnet)
library(caret)
set.seed(123)
# 모델 매트릭스 생성
x_train <- model.matrix(신입생경쟁률~., trainSet)[,-1]
y_train <- trainSet$신입생경쟁률
x_test <- model.matrix(신입생경쟁률~., testSet)[,-1]
y_test <- testSet$신입생경쟁률
# Ridge 회귀
ridge_cv <- cv.glmnet(x_train, y_train, alpha = 0, nfolds = 10)
best_lambda_ridge <- ridge_cv$lambda.min
# Lasso 회귀
lasso_cv <- cv.glmnet(x_train, y_train, alpha = 1, nfolds = 10)
best_lambda_lasso <- lasso_cv$lambda.min
set.seed(123)
# Ridge 예측 및 RMSE 계산
ridge_pred <- predict(ridge_cv, s = best_lambda_ridge, newx = x_train)
ridge_pred_test <- predict(ridge_cv, s = best_lambda_ridge, newx = x_test)
ridge_rmse <- RMSE(ridge_pred, trainSet$신입생경쟁률 )
ridge_rmse_test <- RMSE(ridge_pred_test, testSet$신입생경쟁률)
# Lasso 예측 및 RMSE 계산
lasso_pred <- predict(lasso_cv, s = best_lambda_lasso, newx = x_train)
lasso_pred_test <- predict(lasso_cv, s = best_lambda_lasso, newx = x_test)
lasso_rmse <- RMSE(lasso_pred, trainSet$신입생경쟁률)
lasso_rmse_test <- RMSE(lasso_pred_test, testSet$신입생경쟁률)
print(paste("Ridge RMSE train:", ridge_rmse))
print(paste("Lasso RMSE train:", lasso_rmse))
print(paste("Ridge RMSE test:", ridge_rmse))
print(paste("Lasso RMSE test:", lasso_rmse))
print(paste("Ridge 람다:", best_lambda_lasso))
print(paste("Lasso 람다:", best_lambda_ridge))
ridge_cv
lasso_cv
library(car)
library(pls)
reg_pcr_tt <- lm(신입생경쟁률~ ., data = trainSet)
vif(reg_pcr_tt)
set.seed(123)
cv_pcr <- pcr(신입생경쟁률~. , data = trainSet, scale = TRUE, center = TRUE, validation = "CV")
summary(cv_pcr)
validationplot(cv_pcr)
pcr_pred <- predict(cv_pcr, testSet, ncomp = 21)
RMSE(pcr_pred, testSet$신입생경쟁률)
pcr_pred1 <- predict(cv_pcr, testSet, ncomp = 22)
RMSE(pcr_pred1, testSet$신입생경쟁률)
pcr_pred2 <- predict(cv_pcr, testSet, ncomp = 23)
RMSE(pcr_pred2, testSet$신입생경쟁률)
pcr_pred3 <- predict(cv_pcr, testSet, ncomp = 24)
RMSE(pcr_pred3, testSet$신입생경쟁률)
pcr_pred4 <- predict(cv_pcr, testSet, ncomp = 26)
RMSE(pcr_pred4, testSet$신입생경쟁률)
set.seed(123)
cv_pcr_final2 <- train(신입생경쟁률~. , data = trainSet, method = "pcr", trControl = trainControl (method = "repeatedcv", number = 10, repeats = 10), preProcess = c("center", "scale"), tuneGrid = data.frame(ncomp = 1: 30))
cv_pcr_final2
predict_pcr <- predict(cv_pcr, newdata = trainSet, ncomp = 26)  # ncomp는 최적의 주성분 수
train_rmse_pcr <- RMSE(predict_pcr, trainSet$신입생경쟁률)
predict_pcr_test <- predict(cv_pcr, newdata = testSet, ncomp = 26)  # ncomp는 최적의 주성분 수
test_rmse_pcr <- RMSE(predict_pcr_test, testSet$신입생경쟁률)
print(paste("PCR RMSE train:", train_rmse_pcr))
print(paste("PCR RMSE test:", test_rmse_pcr))
library(vip)
library(caret)
set.seed(123)
model_feature <- lm(신입생경쟁률~. , data =  trainSet)
summary(model_feature)
vip(model_feature)
model_feature2 <- lm(신입생경쟁률~(.)^2+I(전임교원수^2)+I(전임교원확보율^2), data = trainSet)
summary(model_feature2)
vip(model_feature2)
set.seed(123)
fwd_model_feature <- train(신입생경쟁률~(.)^2+I(전임교원수^2)+I(전임교원확보율^2), data = trainSet, method = "leapForward", tuneGrid = data.frame(nvmax = 1:30), trControl = trainControl(method = "repeatedcv", number = 10, repeats = 5 ))
fwd_model_feature
ggplot(fwd_model_feature)
fwd_model_feature$bestTune
coef_bwd_cv_feature <- coef(fwd_model_feature, fwd_model_feature$bestTune$nvmax)
coef_bwd_cv_feature
test_coef_bed_cv_feature <- predict(fwd_model_feature, newdata = trainSet)
RMSE(test_coef_bed_cv_feature, trainSet$신입생경쟁률)
trainX <- model.matrix(신입생경쟁률~(.)^2+I(전임교원수^2)+I(전임교원확보율^2), trainSet)[,-1]
testX <- model.matrix(신입생경쟁률~(.)^2+I(전임교원수^2)+I(전임교원확보율^2), testSet)[,-1]
trainY <- trainSet$신입생경쟁률
testY <- testSet$신입생경쟁률
set.seed(123)
cv_lasso <- cv.glmnet(x = trainX, y = trainY, alpha = 1, nfolds = 10)
plot(cv_lasso)
cv_lasso$lambda.min
cv_lasso$lambda.1se
predict(cv_lasso, s = cv_lasso$lambda.1se, type = "coefficients")
set.seed(123)
lasso_caret_eln <-  train(신입생경쟁률~(.)^2+I(전임교원수^2)+I(전임교원확보율^2), data = trainSet, method = "glmnet", tuneLength = 10 , trControl = trainControl(method = "repeatedcv", number = 10, repeats = 5 , selectionFunction = "oneSE"))
lasso_caret_eln
ggplot(lasso_caret_eln)
library(corrplot)
library(ggplot2)
set.seed(123)
x1 <- rnorm(100, mean = 0, sd=1)
x2 <- rnorm(100, mean = 0, sd=1)
x3 <- rnorm(100, mean = 0, sd=1)
x4 <- rnorm(100, mean = 0, sd=1)
x5 <- rnorm(100, mean = 0, sd=1)
x6 <- rnorm(100, mean = 0, sd=1)
x7 <- rnorm(100, mean = 0, sd=1)
x8 <- rnorm(100, mean = 0, sd=1)
x9 <- rnorm(100, mean = 0, sd=1)
x10 <- rnorm(100, mean = 0, sd=1)
epsilon <- rnorm(100, mean = 0, sd =4)
y <- 1 + 2*x1 - 4*x2^2 + 3*x3^3+epsilon
# 데이터 프레임 준비
data_frame <- data.frame(y, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10)
# 상관계수 계산
cor_y_x <- cor(data_frame[ , 1], data_frame[ , 2:11])
# 상관계수를 바 그래프로 시각화
barplot(cor_y_x, main="Y와 상관관계", xlab="변수들", ylab="상관계수", col='blue')
model <- lm(y ~ ., data = data_frame)
summary(model)
model <- lm(y ~ x1+x2+x3, data = data_frame)
summary(model)
library(caret)
library(glmnet)
set.seed(123)
train_control <- trainControl(method = "cv", number = 10,
summaryFunction = defaultSummary)
lasso_model <- train(y ~ ., data = data_frame, method = "glmnet",
trControl = train_control,
tuneLength = 10,
preProcess = c("center", "scale"),
tuneGrid = expand.grid(alpha = 1,
lambda = 10^seq(-3, -1, length.out = 100)))
best_lambda <- lasso_model$bestTune$lambda
coef <- coef(lasso_model$finalModel, s = best_lambda)
print(paste("Best lambda:", best_lambda))
print("Coefficients:")
print(coef)
plot(lasso_model)
load("C:/Users/ktnu2/데이터애널리스트/과제3/.RData")
