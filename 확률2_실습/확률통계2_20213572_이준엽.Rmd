---
title: "HW_R실습_확통2"
author: "이준엽"
date: "2024-05-25"
output: html_document
---
# R실습 과제

### 라이브러리

```{r warning = FALSE, message = FALSE}

library(knitr)
library(car)
library(ggplot2)
library(qqplotr)
```

## 1.One-way ANOVA

### a) One-way ANOVA를 수행하기 위한 데이터를 수집하세요. 3가지 수준(처리)을 가지는 요인(factor) 하나를 정하고 각 수준별 10개의 반응치를 찾아야 합니다. 완전 확률화 계획법 (completely randomized design)을 만족하도록 반응치의 값들을 구성했는지 기술하세요. (이미 존재하는 데이터 사용 금지. 직접 데이터 수집.)

```{r warning = FALSE, message = FALSE}
# 데이더 생성

# 데이터 생성

set.seed(123)

group1 <- round(rnorm(10, mean = 174, sd = 2), 1)
group2 <- round(rnorm(10, mean = 174, sd = 2), 1)
group3 <- round(rnorm(10, mean = 174, sd = 2), 1)

detas <- data.frame(
  man_h = c(group1, group2, group3),
  group = factor(rep(c("Group1", "Group2", "Group3"), each = 10))
)

# 데이터 확인
print(detas)


```

#### 분석결과

요인 : 남성의 키
수준 3개 : 그룹1, 그룹2, 그룹3

나누어 실험합니다

### b) Box plot을 그려서 대략적인 표본의 분포를 확확인하세요. 


```{r warning = FALSE, message = FALSE}

# 박스 플롯 생성
boxplot(man_h ~ group, data = detas, 
        main = "Box plot으로 남성의 키 알아보기기",
        xlab = "Group", 
        ylab = "Height (man_h)", 
        col = c("lightblue", "lightgreen", "lightcoral"))


summary(detas)

```

### c) 각 처리별 모분산의 동일성을 확인하세요.

```{r warning = FALSE, message = FALSE}

# Levene's Test

leveneTest(man_h ~ group, data = detas)

```

#### 분석결과

동일성 테스트 의 결과 p-value 가 1 입니다. 일반적으로 p-value가 0.05  이상이면 귀무가설을 기각할 수 없습니다. 여기서 귀무가설은 "각 그룹의 모분산이 동일하다"입니다.

따라서, 이 결과는 각 그룹의 모분산이 동일하다는 귀무가설을 기각할 수 없음을 의미합니다. 즉, 주어진 데이터에서 각 그룹의 모분산은 동일하다고 볼 수 있습니다.


### d) 반응치 값들이 정규분포를 따르는지 확인하세요

```{r warning = FALSE, message = FALSE}


# Q-Q 플롯 생성 
qq_plot <- ggplot(detas, aes(sample = man_h)) +
  stat_qq_band(alpha = 0.5) +
  stat_qq_line() +
  stat_qq_point() +
  facet_wrap(~ group) +
  labs(title = "Q-Q Plot 그룹별 신뢰구간",
       x = "Theoretical Quantiles",
       y = "Sample Quantiles") +
  theme_minimal()

# Q-Q 플롯 출력
print(qq_plot)

# Shapiro-Wilk Test
shapiro.test(detas$man_h[detas$group == "Group1"])
shapiro.test(detas$man_h[detas$group == "Group2"])
shapiro.test(detas$man_h[detas$group == "Group3"])



```


#### 분석결과


대체로 그룹들이 신뢰구간에 점들이 찍혀 있습니다.  이는 전체적으로 볼 때 정규분포를 따르고 있다고 판단할 수 있습니다. 

### e) 분산분석을 수행하여 처리별 모평균의 차이가 있는지 검정하세요.

```{r warning = FALSE, message = FALSE}

# One-way ANOVA
anova_result <- aov(man_h ~ group, data = detas)
summary(anova_result)


```
#### 분석결과

 여기서 귀무가설(모평군에 차이가 없다)이 참이라는 가정하에, 
F 값이 나타낼 확률을 의미 합니다.

따라서 p-value (0.318) 이 일반적인 유의수준 0.005보다 크므로, 귀무가설 기각할 수 없습니다. 

데이터에서 그룹 간의 모평균 차이는 유의미하지 않습니다. 


### f)모평균의 차이가 있다면, Bonferroni 방법을 이용한 사후검정을 통해 어떤 처리 사이에 모평균의 차이가 있는지 확인하세요.

```{r warning = FALSE, message = FALSE}

# Bonferroni post-hoc test

pairwise.t.test(detas$man_h, detas$group, p.adjust.method = "bonferroni")


```


## 2.ANOVA for Randomized Block Design


### a) Randomized block design에 대해 ANOVA를 수행할 수 있도록 데이터를 수집하세요. 3가지 수준을 가지는 요인을 하나 정하고, block의 개수는 4개가 되도록 합니다. Randomized block design에 맞게 반응치의 값들을 구성했는지 기술하세요. (이미 존재하는 데이터 사용 금지. 직접 데이터 수집. )


#### 분석예시)

- 3개의 다른 음식에 매운 자극 대한 반응 시간의 차이를 알아보기 위한 실험이 4명의 실험 자(block) 에 대한 randomized
block design 으로 설계 되었다.

```{r warning = FALSE, message = FALSE}
# 데이터 생성
set.seed(123)

mydata <- data.frame(
         time = c(1.5, 1.8, 2.1,   
               # Block1: Treatment1, reatment2,Treatment3
               1.6, 1.9, 2.2,   
               # Block2: Treatment1, Treatment2, Treatment3
               1.4, 1.7, 2.0,   
               # Block3: Treatment1, Treatment2, Treatment3
               1.3, 1.6, 1.9),  
              # Block4: Treatment1, Treatment2, Treatment3
  treatment = c(rep("Treatment1", 4), rep("Treatment2",4), rep("Treatment3", 4)),
  block = rep(c("Block1", "Block2", "Block3", "Block4"), each = 3))
  
head(mydata, 5)

```

### b) 처리와 block을 모두 고려하여 ANOVA를 수행하고 결과를 분석하세요.
 
```{r warning = FALSE, message = FALSE}

# 블록과 처리를 고려한 ANOVA 수행
anova_block <- aov(time ~ treatment + block, data = mydata)
summary(anova_block)

```
#### 분석결과

treatment에 대한 일반적인 유의수준 보다 큽니다.  자극의 차이가 시간에 영향을 미친다고 할 수 없습니다.

블럭 대한 p-value 도 매우 큰 값을 가지기 때문에 영향이 없다고 할 수 있습니다.

처리 수준과 블록 간의 실제 차이가 작은경우, 또는 잔차 변동성이 큰  경우 유의미한 차이를 못 낼수도 있습니다. 


### c) block을 고려하지 않는 ANOVA를 수행하고, (b)의 결과와 비교하여 분석하세요


```{r warning = FALSE, message = FALSE}

# 블록을 고려하지 않은 ANOVA 수행
anova_no_block <- aov(time ~ treatment, data = mydata)
anova_no_block_summary <- summary(anova_no_block)
print(anova_no_block_summary)


```

treatment  에 대한 p-value 가 일반적인 유의수준 보다 큽니다. 
즉 귀무가설을 기각할 수 없으므로 영향이 없다고 봅니다.



## 3.Simple Linear Regression

```{r warning = FALSE, message = FALSE}

set.seed(123)

# 독립변수 생성
x <- runif(100, 0, 10)

# 종속변수 생성
epsilon <- rnorm(100, mean = 0, sd = 4)
y <- 2 * x - 3 + epsilon

# 데이터 프레임 생성
data <- data.frame(x = x, y = y)

# 데이터 확인
head(data)


```

###  b) β1 (추정) 은 얼마인가요? 그리고 b1에 대한 95% 신뢰구간을 찾으세요. 이 구간이 실제 β1 = 2 를 포함하나요?

 
```{r warning = FALSE, message = FALSE}

# 선형 회귀 모델 적합
model <- lm(y ~ x, data = data)

# 회귀 계수와 95% 신뢰구간 추정
summary(model)
confint(model, level = 0.95)


```

#### 분석결과

b1에 추정치는 1.9641 입니다. 신뢰구간은 [1.692734, 2.235401] 로 2를 포합니다.


### c) 100개의 데이터를 그림으로 표시하고, 그 위에 실제 회귀식과 데이터로부터 추정한 회귀식을 그리세요.


```{r warning = FALSE, message = FALSE}



# 데이터와 회귀선 시각화
ggplot(data, aes(x = x, y = y)) +
  geom_point() +
  geom_smooth(method = "lm", col = "blue") +
  geom_abline(intercept = -3, slope = 2, col = "red", linetype = "dashed") +
  labs(title = "Scatter plot with Regression Line",
       x = "추정한 회귀식 (x)",
       y = "실제 회귀식 (y)") +
  theme_minimal()



```



###  d) a)와 b)를 10번 반복한 후, b1(추정)과 b1(실제)에 대한 95% 신뢰구간을 표로 정리하고, 결과를 분석하세요

```{r warning = FALSE, message = FALSE}


# 결과 저장용 데이터 프레임 생성
results <- data.frame(iteration = integer(0), beta1_hat = numeric(0), ci_lower = numeric(0), ci_upper = numeric(0))

for (i in 1:10) {
  # 데이터 생성
  x <- runif(100, 0, 10)
  epsilon <- rnorm(100, mean = 0, sd = 4)
  y <- 2 * x - 3 + epsilon
  data <- data.frame(x = x, y = y)
  
  # 선형 회귀 모델 적합
  model <- lm(y ~ x, data = data)
  
  # 회귀 계수와 95% 신뢰구간 추정
  beta1_hat <- coef(model)["x"]
  conf_int <- confint(model, level = 0.95)["x", ]
  
  # 결과 저장
  results <- rbind(results, data.frame(iteration = i, beta1_hat = beta1_hat, ci_lower = conf_int[1], ci_upper = conf_int[2]))
}

# 결과 확인
print(results)

# 신뢰구간이 실제 beta1 = 2를 포함하는지 확인
results$includes_beta1 <- (results$ci_lower <= 2 & results$ci_upper >= 2)

# 결과 출력
print(results)

# 분석 결과 요약
cat("10번 반복 중 신뢰구간에 실제 beta1 = 2를 포함한 횟수:", sum(results$includes_beta1), "번\n")



```


##  4. Multiple Linear Regression 

### a) Sepal.Width를 종속변수로, Sepal.Length, Petal.Length, Petal.Width를 독립변수로 설정하여 multiple linear regression을 수행해 보자. regression의 결과를 분석해 보세요.

```{r warning = FALSE, message = FALSE}

# 데이터셋 로드
data(iris)

# 다중 회귀분석 수행
model <- lm(Sepal.Width ~ Sepal.Length + Petal.Length + Petal.Width, data = iris)

# 회귀분석 결과 요약
summary(model)

```
#### 분석결과

Sepal.Width 종속변수 대해 독립변수들 모두가 유의미하는 것 알 수 있습니다. 

잔차의 표준 오차는 0.3038로 비교적 낮습니다.

MSE 는 0.3038^2 , 자유도는 n -2 = 146

변동(R^2)을 약 52.4% 설명할 수 있습니다. 

F = MSR / MSE 는 53.58 입니다.

F-통계량과 그에 따른 p-value는 모델이 전체적으로 유의미함을 나타냅니다.


### b) Residual plot을 출력하고, 어떠한 문제가 있는지 진단해 보세요.

```{r warning = FALSE, message = FALSE}

 # "적합값 대 잔차" 플롯 함수 정의
plot_residuals <- function(model, title) {
  residuals_data <- data.frame(
    fitted = fitted(model),
    residuals = residuals(model)
  )
  
  ggplot(residuals_data, aes(x = fitted, y = residuals)) +
    geom_point() +
    geom_smooth(method = "loess", se = FALSE, color = "red") +
    labs(title = title, x = "적합값", y = "잔차") +
    theme_minimal()
}

# 기본 모델의 "적합값 대 잔차" 플롯 출력
plot_residuals(model, "기본 모형: 적합값 대 잔차")
```



#### 분석결과


직선형태가 아닌 곡선의 형태로 가지고 있습니다. 
이 경우에는 독립변수의제곱항이 생략되어 있을 가능성 있습니다.


### c) a)에서 사용한 독립변수들의 제곱항을 모두 추가하여 multiple linear regression을 수행해 보자.

```{r warning = FALSE, message = FALSE}

# 제곱항을 추가한 다중 회귀분석 수행
model_poly <- lm(Sepal.Width ~ Sepal.Length + I(Sepal.Length^2) +
                                  Petal.Length + I(Petal.Length^2) +
                                  Petal.Width + I(Petal.Width^2), data = iris)

# 회귀분석 결과 요약
summary(model_poly)



```
#### 분석결과

잔차 오차(MSE)는 0.2755 , 자유도는 n- 2 = 143

결정계수는 61.67 입니다. 

F = MSR / MSE 는 38.35 입니다다

### d) 종속변수에 통계적으로 영향을 미치는 변수는 어떤 변수들인가요? 그리고 두 모형 중 어떤 모형이 종속변수의 변동을 더 잘 설명하나요?


```{r warning = FALSE, message = FALSE}

# 두 모델의 R-squared 값을 비교하는 표 생성
r_squared_comparison <- data.frame(
  모델 = c("기본 모형", "제곱항 추가 모형"),
  R_squared = c(summary(model)$r.squared, summary(model_poly)$r.squared)
)

# 표 출력
kable(r_squared_comparison, caption = "기본 모형과 제곱항 추가 모형의 R-squared 값 비교")

```

### e) Residual plot을 출력하고, b)번에 비해서 어떤 변화가 있는지 분석하세요



```{r warning = FALSE, message = FALSE}



# 기본 모델의 "적합값 대 잔차" 플롯 출력
plot_residuals(model, "기본 모형: 적합값 대 잔차")

# 제곱항 추가한 모델의 "적합값 대 잔차" 플롯 출력
plot_residuals(model_poly, "제곱항 추가 모형: 적합값 대 잔차")

```


#### 분석결과

전 보다 약한 패턴을 가짐을 알 수 있습니다. 이 경우에 더 신뢰할 수 있는 선형회귀 모델은 갖습니다다
