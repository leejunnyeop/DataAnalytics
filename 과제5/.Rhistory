test$y <- factor(test$y)
# confusionMatrix를 사용하여 정확도 계산
accuracy <- confusionMatrix(pred, test$y)$overall['Accuracy']
# 가지치기된 트리 모델로 예측
pred <- predict(pruned_tree, newdata = test, type = "class")
# 예측값과 실제값을 팩터로 변환하고 동일한 레벨로 맞추기
pred <- factor(pred, levels = levels(factor(test$y)))
# confusionMatrix를 사용하여 정확도 계산
accuracy <- confusionMatrix(pred, test$y)$overall['Accuracy']
print(accuracy)
# Bagging 모델 생성 (mtry를 전체 변수의 수로 설정)
bagging_model <- randomForest(y ~ ., data = train, mtry = ncol(train_x), importance = TRUE)
# Bagging 모델 생성 (mtry를 전체 변수의 수로 설정)
bagging_model <- randomForest(y ~ ., data = train, mtry = ncol(train_x), importance = TRUE)
# 변수 중요도 시각화
importance <- importance(bagging_model)
importance_df <- data.frame(Feature = rownames(importance), Importance = importance[,1])
# 중요도가 높은 순으로 정렬
importance_df <- importance_df[order(importance_df$Importance, decreasing = TRUE),]
# 상위 20개 변수만 선택
top_20 <- head(importance_df, 20)
# 중요도 시각화
ggplot(top_20, aes(x = reorder(Feature, Importance), y = Importance)) +
geom_bar(stat = "identity") +
coord_flip() +
xlab("Feature") +
ylab("Importance") +
ggtitle("Top 20 Important Features in Bagging Model")
# Bagging 모델로 예측
bagging_pred <- predict(bagging_model, newdata = test)
# 예측값과 실제값을 팩터로 변환하고 동일한 레벨로 맞추기
bagging_pred <- factor(bagging_pred, levels = levels(factor(test$y)))
# Bagging 모델의 정확도 계산
bagging_accuracy <- confusionMatrix(bagging_pred, factor(test_y))$overall['Accuracy']
print(bagging_accuracy)
# Random Forest 모델 생성 (기본 옵션 사용)
rf_model <- randomForest(y ~ ., data = train)
# Bagging 모델과 Random Forest 모델의 OOB 오류율 추출
bagging_oob_error <- bagging_model$err.rate[, "OOB"]
rf_oob_error <- rf_model$err.rate[, "OOB"]
# OOB 오류율 데이터프레임 생성
oob_df <- data.frame(
Trees = 1:length(bagging_oob_error),
Bagging = bagging_oob_error,
RandomForest = rf_oob_error
)
# OOB 오류율 시각화
ggplot(oob_df, aes(x = Trees)) +
geom_line(aes(y = Bagging, color = "Bagging")) +
geom_line(aes(y = RandomForest, color = "Random Forest")) +
labs(title = "OOB Error Rate vs. Number of Trees",
x = "Number of Trees",
y = "OOB Error Rate") +
scale_color_manual(values = c("Bagging" = "red", "Random Forest" = "blue")) +
theme_minimal()
# Bagging 모델로 예측
rf_pred <- predict(bagging_model, newdata = test)
# 예측값과 실제값을 팩터로 변환하고 동일한 레벨로 맞추기
rf_pred <- factor(bagging_pred, levels = levels(factor(test$y)))
# Random Forest 모델의 정확도 계산
rf_accuracy <- confusionMatrix(rf_pred, factor(test_y))$overall['Accuracy']
print(paste("Random Forest Model Accuracy:", rf_accuracy))
# 성능 향상 계산
performance_improvement <- rf_accuracy - bagging_accuracy
print(paste("Performance Improvement:", performance_improvement))
# Bagging 모델로 예측
rf_pred <- predict(rf_model, newdata = test)
# 예측값과 실제값을 팩터로 변환하고 동일한 레벨로 맞추기
rf_pred <- factor(rf_model, levels = levels(factor(test$y)))
# Random Forest 모델의 정확도 계산
rf_accuracy <- confusionMatrix(rf_pred, factor(test_y))$overall['Accuracy']
# Bagging 모델로 예측
rf_pred <- predict(rf_model, newdata = test)
# 예측값과 실제값을 팩터로 변환하고 동일한 레벨로 맞추기
rf_pred <- factor(rf_model, levels = levels(factor(test$y)))
# Random Forest 모델의 정확도 계산
rf_accuracy <- confusionMatrix(rf_pred, factor(test_y))$overall['Accuracy']
# 다양한 숲 모델로 예측
rf_pred <- predict(rf_model, newdata = test)
# 예측값과 실제값을 팩터로 변환하고 동일한 레벨로 맞추기
rf_pred <- factor(rf_pred, levels = levels(factor(test$y)))
# Random Forest 모델의 정확도 계산
rf_accuracy <- confusionMatrix(rf_pred, factor(test_y))$overall['Accuracy']
print(paste("Random Forest Model Accuracy:", rf_accuracy))
# 무작위 숲 모델로 예측
rf_pred <- predict(rf_model, newdata = test)
# 예측값과 실제값을 팩터로 변환하고 동일한 레벨로 맞추기
rf_pred <- factor(rf_pred, levels = levels(factor(test$y)))
# Random Forest 모델의 정확도 계산
rf_accuracy <- confusionMatrix(rf_pred, factor(test_y))$overall['Accuracy']
print(paste("무작위 숲 Model Accuracy:", rf_accuracy))
# 성능 향상 계산
performance_improvement <- rf_accuracy - bagging_accuracy
print(paste("Performance Improvement:", performance_improvement))
# 혼동 행렬 계산
conf_matrix <- confusionMatrix(rf_pred, factor(test_y))
# 클래스별 정확도 계산
class_accuracies <- diag(conf_matrix$table) / rowSums(conf_matrix$table)
# 가장 정확한 숫자와 가장 어려운 숫자 찾기
most_accurate_digit <- names(which.max(class_accuracies))
least_accurate_digit <- names(which.min(class_accuracies))
# 출력
print(paste("Most Accurate Digit:", most_accurate_digit, "with accuracy", max(class_accuracies)))
print(paste("Least Accurate Digit:", least_accurate_digit, "with accuracy", min(class_accuracies)))
# 잘못 분류된 데이터 찾기
misclassified_indices <- which(test_y == 7 & rf_pred == 1)
# 잘못 분류된 데이터 중 일부를 선택하여 시각화
num_images_to_plot <- min(length(misclassified_indices), 4)  # 최대 4개의 이미지를 시각화
par(mfrow = c(2, 2))  # 2x2 그래프 레이아웃 설정
# 잘못 분류된 데이터 찾기
misclassified_indices <- which(test_y == 7 & rf_pred == 1)
# 잘못 분류된 데이터 중 일부를 선택하여 시각화
num_images_to_plot <- min(length(misclassified_indices), 4)  # 최대 4개의 이미지를 시각화
par(mfrow = c(2, 2))  # 2x2 그래프 레이아웃 설정
for (i in 1:num_images_to_plot) {
index <- misclassified_indices[i]
image_matrix <- matrix(test_x[index, ], nrow = 28, byrow = TRUE)
image_matrix <- t(apply(image_matrix, 2, rev))  # 이미지를 올바르게 회전
image(1:28, 1:28, image_matrix, col = gray(seq(0, 1, length = 256)), xlab = "", ylab = "")
title(main = paste("Index:", index))
}
# 잘못 분류된 데이터 찾기
misclassified_indices <- which(test_y == 7 & rf_pred == 1)
# 잘못 분류된 데이터 중 일부를 선택하여 시각화
num_images_to_plot <- min(length(misclassified_indices), 4)  # 최대 4개의 이미지를 시각화
par(mfrow = c(2, 2))  # 2x2 그래프 레이아웃 설정
for (i in 1:num_images_to_plot) {
index <- misclassified_indices[i]
image_matrix <- matrix(as.numeric(test_x[index, ]), nrow = 28, ncol = 28, byrow = TRUE)
image(1:28, 1:28, t(apply(image_matrix, 2, rev)), col = gray(seq(0, 1, length = 256)), xlab = "", ylab = "")
title(main = paste("Index:", index))
}
rm(list = ls())
# 라이브러리 추가
library(caret)
library(dslabs)
library(rpart)
library(rpart.plot)
library(randomForest)
# 1A. mnist 데이터 읽기
mnist <- read_mnist()
# 1B. training set에서 첫 2000개의 데이터 추출
train_x <- mnist$train$image[1:2000,]
train_y <- factor(mnist$train$labels[1:2000])
# label 분포 확인
table(train_y)
# 시각화
ggplot(as.data.frame(train_y), aes(x=train_y)) + geom_bar() + labs(x="labels")
# 1B. training set에서 첫 2000개의 데이터 추출
seed.is(123)
# 1B. training set에서 첫 2000개의 데이터 추출
seed.id(123)
# 1B. training set에서 첫 2000개의 데이터 추출
set.seed(123)
train_x <- mnist$train$image[1:2000,]
train_y <- factor(mnist$train$labels[1:2000])
# label 분포 확인
table(train_y)
# 시각화
ggplot(as.data.frame(train_y), aes(x=train_y)) + geom_bar() + labs(x="labels")
# 1C. train_x의 변수 이름 세팅
colnames(train_x) <- paste0("V", 1:ncol(train_x))
# 1D. variance가 0에 가까운 feature 제외
nzv <- nearZeroVar(train_x)
length(nzv)
train_x <- train_x[, -nzv]
# 1E. training set data frame 생성
train <- data.frame(train_x, y = train_y)
# 1F. test set data frame 생성
test_x <- mnist$test$images
test_y <- mnist$test$labels
colnames(test_x) <- paste0("V", 1:ncol(test_x))
test_x <- test_x[, -nzv]
test <- data.frame(test_x, y = test_y)
# 2. 이미지 출력 함수 작성
print_image <- function(num){image(1:28, 1:28, matrix(mnist$test$images[num,], nrow=28)[ , 28:1], col = gray(seq(0, 1, 0.05)), xlab = "", ylab="")}
# 이미지와 실제 label 비교
print_image(9)
print_image(19)
print_image(42)
test_y[9]
test_y[19]
test_y[42]
# 필요한 패키지 로드
library(rpart)
library(caret)
library(randomForest)
library(rpart.plot)
head(train)
# 결정 트리 모델 생성
tree_model <- rpart(y ~ ., data = train, method = "class")
# 가지치기
printcp(tree_model)  # 교차 검증 결과 출력
optimal_cp <- tree_model$cptable[which.min(tree_model$cptable[,"xerror"]),"CP"]
pruned_tree <- prune(tree_model, cp = optimal_cp)
# rpart.plot 패키지를 사용하여 가지치기 후 모델 시각화
rpart.plot(pruned_tree, type = 4, extra = 101, cex = 0.4)
text(pruned_tree, use.n = TRUE, all = TRUE, cex = .8)
# 가지치기된 트리 모델로 예측
pred <- predict(pruned_tree, newdata = test, type = "class")
# 예측값과 실제값을 팩터로 변환하고 동일한 레벨로 맞추기
pred <- factor(pred, levels = levels(factor(test$y)))
# confusionMatrix를 사용하여 정확도 계산
accuracy <- confusionMatrix(pred, test$y)$overall['Accuracy']
# 가지치기된 트리 모델로 예측
pred <- predict(pruned_tree, newdata = test, type = "class")
# confusionMatrix를 사용하여 정확도 계산
accuracy <- confusionMatrix(pred, test$y)$overall['Accuracy']
# 가지치기된 트리 모델로 예측
pred <- predict(pruned_tree, newdata = test, type = "class")
# 예측값과 실제값을 팩터로 변환하고 동일한 레벨로 맞추기
pred <- factor(pred, levels = levels(factor(test$y)))
# confusionMatrix를 사용하여 정확도 계산
accuracy <- confusionMatrix(pred, test$y)$overall['Accuracy']
rm(list =ls())
# 라이브러리 추가
library(caret)
library(dslabs)
library(rpart)
library(rpart.plot)
library(randomForest)
# 1A. mnist 데이터 읽기
mnist <- read_mnist()
# 1B. training set에서 첫 2000개의 데이터 추출
set.seed(123)
train_x <- mnist$train$image[1:2000,]
train_y <- factor(mnist$train$labels[1:2000])
# label 분포 확인
table(train_y)
# 시각화
ggplot(as.data.frame(train_y), aes(x=train_y)) + geom_bar() + labs(x="labels")
# 1D. variance가 0에 가까운 feature 제외
nzv <- nearZeroVar(train_x)
length(nzv)
train_x <- train_x[, -nzv]
# 1E. training set data frame 생성
train <- data.frame(train_x, y = train_y)
# 1E. training set data frame 생성
train <- data.frame(train_x, y = train_y)
# 1F. test set data frame 생성
test_x <- mnist$test$images
test_y <- mnist$test$labels
colnames(test_x) <- paste0("V", 1:ncol(test_x))
test_x <- test_x[, -nzv]
test <- data.frame(test_x, y = test_y)
# 2. 이미지 출력 함수 작성
print_image <- function(num){image(1:28, 1:28, matrix(mnist$test$images[num,], nrow=28)[ , 28:1], col = gray(seq(0, 1, 0.05)), xlab = "", ylab="")}
# 이미지와 실제 label 비교
print_image(9)
print_image(19)
print_image(42)
test_y[9]
test_y[19]
test_y[42]
# 필요한 패키지 로드
library(rpart)
library(caret)
library(randomForest)
library(rpart.plot)
head(train)
# 결정 트리 모델 생성
tree_model <- rpart(y ~ ., data = train, method = "class")
# 가지치기
printcp(tree_model)  # 교차 검증 결과 출력
optimal_cp <- tree_model$cptable[which.min(tree_model$cptable[,"xerror"]),"CP"]
pruned_tree <- prune(tree_model, cp = optimal_cp)
# rpart.plot 패키지를 사용하여 가지치기 후 모델 시각화
rpart.plot(pruned_tree, type = 4, extra = 101, cex = 0.4)
text(pruned_tree, use.n = TRUE, all = TRUE, cex = .8)
# 가지치기된 트리 모델로 예측
pred <- predict(pruned_tree, newdata = test, type = "class")
# 가지치기된 트리 모델로 예측
pred <- predict(pruned_tree, newdata = test, type = "class")
# Bagging 모델 생성 (mtry를 전체 변수의 수로 설정)
bagging_model <- randomForest(y ~ ., data = train, mtry = ncol(train_x), importance = TRUE)
# Bagging 모델 생성 (mtry를 전체 변수의 수로 설정)
bagging_model <- randomForest(y ~ ., data = train, mtry = ncol(train_x), importance = TRUE)
# Bagging 모델 생성 (mtry를 전체 변수의 수로 설정)
bagging_model <- randomForest(y ~ ., data = train, mtry = ncol(train_x), importance = TRUE)
rm(list = ls())
# 라이브러리 추가
library(caret)
library(dslabs)
library(rpart)
library(rpart.plot)
library(randomForest)
# 1A. mnist 데이터 읽기
mnist <- read_mnist()
# 1B. training set에서 첫 2000개의 데이터 추출
set.seed(123)
train_x <- mnist$train$image[1:2000,]
train_y <- factor(mnist$train$labels[1:2000])
# label 분포 확인
table(train_y)
# 시각화
ggplot(as.data.frame(train_y), aes(x=train_y)) + geom_bar() + labs(x="labels")
# 1C. train_x의 변수 이름 세팅
colnames(train_x) <- paste0("V", 1:ncol(train_x))
# 1D. variance가 0에 가까운 feature 제외
nzv <- nearZeroVar(train_x)
length(nzv)
train_x <- train_x[, -nzv]
# 1E. training set data frame 생성
train <- data.frame(train_x, y = train_y)
# 1F. test set data frame 생성
test_x <- mnist$test$images
test_y <- mnist$test$labels
colnames(test_x) <- paste0("V", 1:ncol(test_x))
test_x <- test_x[, -nzv]
test <- data.frame(test_x, y = test_y)
# 2. 이미지 출력 함수 작성
print_image <- function(num){image(1:28, 1:28, matrix(mnist$test$images[num,], nrow=28)[ , 28:1], col = gray(seq(0, 1, 0.05)), xlab = "", ylab="")}
# 이미지와 실제 label 비교
print_image(9)
print_image(19)
print_image(42)
test_y[9]
test_y[19]
test_y[42]
# 필요한 패키지 로드
library(rpart)
library(caret)
library(randomForest)
library(rpart.plot)
# 결정 트리 모델 생성
tree_model <- rpart(y ~ ., data = train, method = "class")
# 가지치기
printcp(tree_model)  # 교차 검증 결과 출력
optimal_cp <- tree_model$cptable[which.min(tree_model$cptable[,"xerror"]),"CP"]
pruned_tree <- prune(tree_model, cp = optimal_cp)
# rpart.plot 패키지를 사용하여 가지치기 후 모델 시각화
rpart.plot(pruned_tree, type = 4, extra = 101, cex = 0.4)
text(pruned_tree, use.n = TRUE, all = TRUE, cex = .8)
# 가지치기된 트리 모델로 예측
pred <- predict(pruned_tree, newdata = test, type = "class")
# 예측값과 실제값을 팩터로 변환하고 동일한 레벨로 맞추기
pred <- factor(pred, levels = levels(factor(test$y)))
# confusionMatrix를 사용하여 정확도 계산
accuracy <- confusionMatrix(pred, test$y)$overall['Accuracy']
# 가지치기된 트리 모델로 예측
pred <- predict(pruned_tree, newdata = test, type = "class")
# 예측값과 실제값을 팩터로 변환하고 동일한 레벨로 맞추기
pred <- factor(pred, levels = levels(factor(test$y)))
# confusionMatrix를 사용하여 정확도 계산
accuracy <- confusionMatrix(pred, test$y)$overall['Accuracy']
# 가지치기된 트리 모델로 예측
pred <- predict(pruned_tree, newdata = test, type = "class")
# 예측값과 실제값을 팩터로 변환하고 동일한 레벨로 맞추기
#pred <- factor(pred, levels = levels(factor(test$y)))
# confusionMatrix를 사용하여 정확도 계산
accuracy <- confusionMatrix(pred, test$y)$overall['Accuracy']
# 가지치기된 트리 모델로 예측
pred <- predict(pruned_tree, newdata = test, type = "class")
# 예측값과 실제값을 팩터로 변환하고 동일한 레벨로 맞추기
levels_pred <- levels(factor(test$y))
pred <- factor(pred, levels = levels_pred)
test$y <- factor(test$y, levels = levels_pred)
# confusionMatrix를 사용하여 정확도 계산
accuracy <- confusionMatrix(pred, test$y)$overall['Accuracy']
print(accuracy)
# Bagging 모델 생성 (mtry를 전체 변수의 수로 설정)
bagging_model <- randomForest(y ~ ., data = train, mtry = ncol(train_x), importance = TRUE)
# Bagging 모델로 예측
bagging_pred <- predict(bagging_model, newdata = test)
# 예측값과 실제값을 팩터로 변환하고 동일한 레벨로 맞추기
bagging_pred <- factor(bagging_pred, levels = levels(factor(test$y)))
# Bagging 모델의 정확도 계산
bagging_accuracy <- confusionMatrix(bagging_pred, factor(test_y))$overall['Accuracy']
print(bagging_accuracy)
# Random Forest 모델 생성 (기본 옵션 사용)
rf_model <- randomForest(y ~ ., data = train)
# Bagging 모델과 Random Forest 모델의 OOB 오류율 추출
bagging_oob_error <- bagging_model$err.rate[, "OOB"]
rf_oob_error <- rf_model$err.rate[, "OOB"]
# OOB 오류율 데이터프레임 생성
oob_df <- data.frame(
Trees = 1:length(bagging_oob_error),
Bagging = bagging_oob_error,
RandomForest = rf_oob_error
)
# OOB 오류율 시각화
ggplot(oob_df, aes(x = Trees)) +
geom_line(aes(y = Bagging, color = "Bagging")) +
geom_line(aes(y = RandomForest, color = "Random Forest")) +
labs(title = "OOB Error Rate vs. Number of Trees",
x = "Number of Trees",
y = "OOB Error Rate") +
scale_color_manual(values = c("Bagging" = "red", "Random Forest" = "blue")) +
theme_minimal()
rm(list = ls())
# 라이브러리 추가
library(caret)
library(dslabs)
library(rpart)
library(rpart.plot)
library(randomForest)
# 1A. mnist 데이터 읽기
mnist <- read_mnist()
# 1B. training set에서 첫 2000개의 데이터 추출
set.seed(123)
train_x <- mnist$train$image[1:2000,]
train_y <- factor(mnist$train$labels[1:2000])
# label 분포 확인
table(train_y)
# 시각화
ggplot(as.data.frame(train_y), aes(x=train_y)) + geom_bar() + labs(x="labels")
# 1C. train_x의 변수 이름 세팅
colnames(train_x) <- paste0("V", 1:ncol(train_x))
# 1D. variance가 0에 가까운 feature 제외
nzv <- nearZeroVar(train_x)
length(nzv)
train_x <- train_x[, -nzv]
# 1E. training set data frame 생성
train <- data.frame(train_x, y = train_y)
# 1F. test set data frame 생성
test_x <- mnist$test$images
test_y <- mnist$test$labels
colnames(test_x) <- paste0("V", 1:ncol(test_x))
test_x <- test_x[, -nzv]
test <- data.frame(test_x, y = test_y)
# 2. 이미지 출력 함수 작성
print_image <- function(num){image(1:28, 1:28, matrix(mnist$test$images[num,], nrow=28)[ , 28:1], col = gray(seq(0, 1, 0.05)), xlab = "", ylab="")}
# 이미지와 실제 label 비교
print_image(9)
print_image(19)
print_image(42)
test_y[9]
test_y[19]
test_y[42]
# 필요한 패키지 로드
library(rpart)
library(caret)
library(randomForest)
library(rpart.plot)
# 결정 트리 모델 생성
tree_model <- rpart(y ~ ., data = train, method = "class")
# 가지치기
printcp(tree_model)  # 교차 검증 결과 출력
optimal_cp <- tree_model$cptable[which.min(tree_model$cptable[,"xerror"]),"CP"]
pruned_tree <- prune(tree_model, cp = optimal_cp)
# rpart.plot 패키지를 사용하여 가지치기 후 모델 시각화
rpart.plot(pruned_tree, type = 4, extra = 101, cex = 0.4)
text(pruned_tree, use.n = TRUE, all = TRUE, cex = .8)
# 가지치기된 트리 모델로 예측
pred <- predict(pruned_tree, newdata = test, type = "class")
# 예측값과 실제값을 팩터로 변환하고 동일한 레벨로 맞추기
levels_pred <- levels(factor(test$y))
pred <- factor(pred, levels = levels_pred)
test$y <- factor(test$y, levels = levels_pred)
# confusionMatrix를 사용하여 정확도 계산
accuracy <- confusionMatrix(pred, test$y)$overall['Accuracy']
print(accuracy)
# Bagging 모델 생성 (mtry를 전체 변수의 수로 설정)
bagging_model <- randomForest(y ~ ., data = train, mtry = ncol(train_x), importance = TRUE)
# Bagging 모델로 예측
bagging_pred <- predict(bagging_model, newdata = test)
# 예측값과 실제값을 팩터로 변환하고 동일한 레벨로 맞추기
bagging_pred <- factor(bagging_pred, levels = levels(factor(test$y)))
# Bagging 모델의 정확도 계산
bagging_accuracy <- confusionMatrix(bagging_pred, factor(test_y))$overall['Accuracy']
print(bagging_accuracy)
# Random Forest 모델 생성 (기본 옵션 사용)
rf_model <- randomForest(y ~ ., data = train)
# Bagging 모델과 Random Forest 모델의 OOB 오류율 추출
bagging_oob_error <- bagging_model$err.rate[, "OOB"]
rf_oob_error <- rf_model$err.rate[, "OOB"]
# OOB 오류율 데이터프레임 생성
oob_df <- data.frame(
Trees = 1:length(bagging_oob_error),
Bagging = bagging_oob_error,
RandomForest = rf_oob_error
)
# OOB 오류율 시각화
ggplot(oob_df, aes(x = Trees)) +
geom_line(aes(y = Bagging, color = "Bagging")) +
geom_line(aes(y = RandomForest, color = "Random Forest")) +
labs(title = "OOB Error Rate vs. Number of Trees",
x = "Number of Trees",
y = "OOB Error Rate") +
scale_color_manual(values = c("Bagging" = "red", "Random Forest" = "blue")) +
theme_minimal()
# 무작위 숲 모델로 예측
rf_pred <- predict(rf_model, newdata = test)
# 예측값과 실제값을 팩터로 변환하고 동일한 레벨로 맞추기
rf_pred <- factor(rf_pred, levels = levels(factor(test$y)))
# Random Forest 모델의 정확도 계산
rf_accuracy <- confusionMatrix(rf_pred, factor(test_y))$overall['Accuracy']
print(paste("무작위 숲 Model Accuracy:", rf_accuracy))
# 성능 향상 계산
performance_improvement <- rf_accuracy - bagging_accuracy
print(paste("Performance Improvement:", performance_improvement))
# 혼동 행렬 계산
conf_matrix <- confusionMatrix(rf_pred, factor(test_y))
# 클래스별 정확도 계산
class_accuracies <- diag(conf_matrix$table) / rowSums(conf_matrix$table)
# 가장 정확한 숫자와 가장 어려운 숫자 찾기
most_accurate_digit <- names(which.max(class_accuracies))
least_accurate_digit <- names(which.min(class_accuracies))
# 출력
print(paste("Most Accurate Digit:", most_accurate_digit, "with accuracy", max(class_accuracies)))
print(paste("Least Accurate Digit:", least_accurate_digit, "with accuracy", min(class_accuracies)))
# 잘못 분류된 데이터 찾기
misclassified_indices <- which(test_y == 7 & rf_pred == 1)
# 잘못 분류된 데이터 중 일부를 선택하여 시각화
num_images_to_plot <- min(length(misclassified_indices), 4)  # 최대 4개의 이미지를 시각화
par(mfrow = c(2, 2))  # 2x2 그래프 레이아웃 설정
for (i in 1:num_images_to_plot) {
index <- misclassified_indices[i]
image_matrix <- matrix(as.numeric(test_x[index, ]), nrow = 28, ncol = 28, byrow = TRUE)
image(1:28, 1:28, t(apply(image_matrix, 2, rev)), col = gray(seq(0, 1, length = 256)), xlab = "", ylab = "")
title(main = paste("Index:", index))
}
