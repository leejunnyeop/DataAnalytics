---
title: "Assignment #5"
subtitle: "Data Analysis with Applications"
author: "이준 엽"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document: 
    highlight: pygments
  pdf_document: default
---

<br/>

### Handwritten Digit Recognition
<br/>

MNIST 데이터셋은 image classification model의 성능을 평가하는 데 주로 활용되는 데이터셋으로, 아래 예와 같이 손으로 쓰여진 숫자들의 이미지 70,000개로 구성되어 있다. 이 중에서 60,000개는 training set으로 활용 되며 10,000개는 test set으로 활용된다. 각 데이터는 28 * 28 = 784개의 픽셀의 명암을 0~255 사이의 값으로 표현한 784개의 feature와 0~9 사이의 숫자로 표현되는 target을 포함한다. 본 과제에서는 tree를 활용하여 숫자를 분류하기 위한 classification model을 만들어본다.

<br/>


```{r warning = FALSE, message = FALSE}
# 라이브러리 추가 
library(caret)
library(dslabs)
library(rpart)
library(rpart.plot)
library(randomForest)
```

<br/>

#### 1. 아래의 순서에 따라 data preprocessing을 수행하자.

**A. dslabs 패키지를 설치하고, 다음 코드를 실행하면 mnist 변수에 아래 설명과 같이 데이터가 저장된다.**
      
```{r warning = FALSE, message = FALSE}
# 1A. mnist 데이터 읽기
mnist <- read_mnist()
```

**B. Training set의 데이터 사이즈가 매우 크기 때문에 60,000개의 데이터 중에 처음 2,000개만 사용하자. 이때 feature 데이터는 변수 train_x에 저장하고, target 데이터는 변수 train_y에 저장한다. train_y의 분포를 확인해 보자.**

```{r warning = FALSE, message = FALSE}
# 1B. training set에서 첫 2000개의 데이터 추출
set.seed(123)
train_x <- mnist$train$image[1:2000,]
train_y <- factor(mnist$train$labels[1:2000])

# label 분포 확인
table(train_y)

# 시각화
ggplot(as.data.frame(train_y), aes(x=train_y)) + geom_bar() + labs(x="labels")
```

* 0 ~ 9 값을 가지는 label의 개수가 172 ~ 224개까지 범위를 가지기 때문에 label별로 조금 차이는 있으나 분석에는 크게 무리가 없을 것으로 판단된다. 

<br/>

**C. train_x의 column의 이름을 V1, V2, V3 … 순서대로 설정하자. colnames() 함수를 사용한다.** 

```{r warning = FALSE, message = FALSE}
# 1C. train_x의 변수 이름 세팅
colnames(train_x) <- paste0("V", 1:ncol(train_x))
```

**D. 784개의 픽셀 중에서 숫자와 관련없는 가장자리 부분과 같은 경우는 많은 데이터들에 대해서 같은 색을 가진다. 이러한 픽셀은 숫자를 분류하는 데 크게 영향을 미치지 않으므로 feature에서 제외시키는 것이 합리적이다. caret 패키지의 nearZeroVar(train_x) 함수를 실행하면 train_x의 column들 중에서 variance가 0이거나 0에 가까운 것들의 index를 얻을 수 있다. 이 index에 해당하는 column을 train_x에서 제외시키자. 784개의 feature 중에서 몇개가 제외되었는가?**  

```{r warning = FALSE, message = FALSE}
# 1D. variance가 0에 가까운 feature 제외
nzv <- nearZeroVar(train_x)
length(nzv)
train_x <- train_x[, -nzv]
```

* 784개의 픽셀 중에서 540개가 feature에서 제외되었다. 
<br/>

**E. 최종적으로 train_x와 train_y를 합쳐서 train이라는 이름의 데이터프레임을 만들자.**  

```{r warning = FALSE, message = FALSE}
# 1E. training set data frame 생성
train <- data.frame(train_x, y = train_y)
```

**F. C~E의 과정을 test set에 대해서 동일하게 수행하여 test라는 이름의 데이터프레임을 만들자. 이때 D에서 제외한 feature와 동일한 feature들을 test set에서도 제외시켜야 한다.** 

```{r warning = FALSE, message = FALSE}
# 1F. test set data frame 생성
test_x <- mnist$test$images
test_y <- mnist$test$labels
colnames(test_x) <- paste0("V", 1:ncol(test_x))
test_x <- test_x[, -nzv]
test <- data.frame(test_x, y = test_y)
```

<br/>

#### 2. 아래의 코드는 test set의 첫번째 데이터를 화면에 이미지로 출력해준다. 이를 활용하여 test set의 image 행렬의 행 번호를 입력받아 숫자 이미지를 출력하는 함수 print_image()를 만들어보자. 이 함수를 활용하여 9, 19, 42번째 숫자를 이미지로 출력해보고 실제 label 값과 비교해보자.

```{r warning = FALSE, message = FALSE}
# 2. 이미지 출력 함수 작성
print_image <- function(num){image(1:28, 1:28, matrix(mnist$test$images[num,], nrow=28)[ , 28:1], col = gray(seq(0, 1, 0.05)), xlab = "", ylab="")}

# 이미지와 실제 label 비교 
print_image(9)
print_image(19)
print_image(42)
test_y[9]
test_y[19]
test_y[42]
```

* 9, 12, 42 번째 숫자들을 출력해 본 결과, 눈으로 구분하는 데는 무리가 없으나 5는 6과 비슷하고, 3은 8과 비슷하기 때문에 모델에 의한 구분이 쉽지는 않을 것으로 예상된다. 

<br/>

### 3.Decision tree를 만들어보자.  


```{r warning = FALSE, message = FALSE}
# 필요한 패키지 로드
library(rpart)
library(caret)
library(randomForest)
library(rpart.plot)

```




#### A. rpart() 함수의 default 옵션으로 Tree를 만든 후 cross validation을 활용한 pruning 과정을 수행해보자. 

```{r warning = FALSE, message = FALSE}

# 결정 트리 모델 생성
tree_model <- rpart(y ~ ., data = train, method = "class")

# 가지치기
printcp(tree_model)  # 교차 검증 결과 출력
optimal_cp <- tree_model$cptable[which.min(tree_model$cptable[,"xerror"]),"CP"]
pruned_tree <- prune(tree_model, cp = optimal_cp)

# rpart.plot 패키지를 사용하여 가지치기 후 모델 시각화
rpart.plot(pruned_tree, type = 4, extra = 101, cex = 0.4)


```





#### B. Pruning을 통해 얻은 Tree의 Test set에 대한 정확도는 얼마인가?  

```{r warning = FALSE, message = FALSE}

# 가지치기된 트리 모델로 예측
pred <- predict(pruned_tree, newdata = test, type = "class")

# 예측값과 실제값을 팩터로 변환하고 동일한 레벨로 맞추기
levels_pred <- levels(factor(test$y))
pred <- factor(pred, levels = levels_pred)
test$y <- factor(test$y, levels = levels_pred)

# confusionMatrix를 사용하여 정확도 계산
accuracy <- confusionMatrix(pred, test$y)$overall['Accuracy']
print(accuracy)
```
</br>
#### 분석결과

테스트 데이터에서 약 59.06%의 정확도로 숫자를 분류할 수 있음을 알 수 있습니다.


##### C. randomForest() 함수를 사용하여 bagging model을 만들어보자. mtry를 제외한 옵션은 모두 default 값을 사용한다.


```{r warning = FALSE, message = FALSE}

# Bagging 모델 생성 (mtry를 전체 변수의 수로 설정)
bagging_model <- randomForest(y ~ ., data = train, mtry = ncol(train_x), importance = TRUE)


```

#### D. Bagging model의 Test set에 대한 정확도는 얼마인가? B번의 Tree model에 비해서 성능이 얼마나 향상되었는가?

```{r warning = FALSE, message = FALSE}

# Bagging 모델로 예측
bagging_pred <- predict(bagging_model, newdata = test)

# 예측값과 실제값을 팩터로 변환하고 동일한 레벨로 맞추기
bagging_pred <- factor(bagging_pred, levels = levels(factor(test$y)))


# Bagging 모델의 정확도 계산
bagging_accuracy <- confusionMatrix(bagging_pred, factor(test_y))$overall['Accuracy']
print(bagging_accuracy)

```
#### 분석결과

tree 보다 89.51으로 향상 되었다. 


#### E. randomForest() 함수의 default 옵션을 사용하여 random forest model을 만들어보자. 그리고 Bagging과 random forest 모델의 Tree의 수의 증가에 따른 OOB classification error rate의 변화를 하나의 그래프에 그려보고 두 모델의 성능을 비교해보자. 

```{r warning = FALSE, message = FALSE}
# Random Forest 모델 생성 (기본 옵션 사용)
rf_model <- randomForest(y ~ ., data = train)

# Bagging 모델과 Random Forest 모델의 OOB 오류율 추출
bagging_oob_error <- bagging_model$err.rate[, "OOB"]
rf_oob_error <- rf_model$err.rate[, "OOB"]

# OOB 오류율 데이터프레임 생성
oob_df <- data.frame(
  Trees = 1:length(bagging_oob_error),
  Bagging = bagging_oob_error,
  RandomForest = rf_oob_error
)

# OOB 오류율 시각화
ggplot(oob_df, aes(x = Trees)) +
  geom_line(aes(y = Bagging, color = "Bagging")) +
  geom_line(aes(y = RandomForest, color = "Random Forest")) +
  labs(title = "OOB Error Rate vs. Number of Trees",
       x = "Number of Trees",
       y = "OOB Error Rate") +
  scale_color_manual(values = c("Bagging" = "red", "Random Forest" = "blue")) +
  theme_minimal()

```
##### 분석결과

Random Forest 모델이 Bagging 모델보다 OOB 오류율이 일관되게 낮아, 더 좋은 성능을 보여줍니다. 이는 Random Forest가 각 트리에서 사용할 변수의 부분 집합을 무작위로 선택하여 모델의 다양성을 높이고, 과적합을 방지하는 데 효과적이기 때문입니다. 따라서, 동일한 데이터에 대해 Random Forest 모델이 더 높은 예측 정확도를 제공할 가능성이 높습니다.


#### F.Random forest model의 Test set에 대한 예측 정확도는 얼마인가? Bagging model에 비해서 성능이 얼마나 향상되었는가? 


```{r warning = FALSE, message = FALSE}

# 무작위 숲 모델로 예측
rf_pred <- predict(rf_model, newdata = test)

# 예측값과 실제값을 팩터로 변환하고 동일한 레벨로 맞추기
rf_pred <- factor(rf_pred, levels = levels(factor(test$y)))


# Random Forest 모델의 정확도 계산
rf_accuracy <- confusionMatrix(rf_pred, factor(test_y))$overall['Accuracy']
print(paste("무작위 숲 Model Accuracy:", rf_accuracy))

# 성능 향상 계산
performance_improvement <- rf_accuracy - bagging_accuracy
print(paste("Performance Improvement:", performance_improvement))


```


##### 분석 결과 

Random Forest 모델은 테스트 셋에 대해 91.39%의 높은 정확도를 보였습니다. 이는 모델이 손으로 쓴 숫자를 효과적으로 분류할 수 있음을 나타냅니다.

Random Forest 모델은 Bagging 모델에 비해 성능이 향상되었습니다. 이는 Random Forest 모델이 각 트리에서 사용할 변수의 부분 집합을 무작위로 선택하여 트리의 다양성을 높이고 과적합을 줄이는 데 효과적이기 때문입니다. 이 결과는 Random Forest 모델이 Bagging 모델보다 더 나은 일반화 능력을 가지고 있음을 시사합니다.

따라서, 동일한 데이터에 대해 Random Forest 모델을 사용하는 것이 더 나은 예측 성능을 제공할 수 있습니다.


이는 특히 분류 문제에서 다양한 특징을 갖는 데이터를 다룰 때 유용합니다.




#### G. Random forest model의 결과로부터, 분류가 가장 정확한 숫자는 몇인가? 가장 분류가 어려운 숫자는 몇인가?


```{r warning = FALSE, message = FALSE}


# 혼동 행렬 계산
conf_matrix <- confusionMatrix(rf_pred, factor(test_y))

# 클래스별 정확도 계산
class_accuracies <- diag(conf_matrix$table) / rowSums(conf_matrix$table)

# 가장 정확한 숫자와 가장 어려운 숫자 찾기
most_accurate_digit <- names(which.max(class_accuracies))
least_accurate_digit <- names(which.min(class_accuracies))

# 출력
print(paste("Most Accurate Digit:", most_accurate_digit, "with accuracy", max(class_accuracies)))
print(paste("Least Accurate Digit:", least_accurate_digit, "with accuracy", min(class_accuracies)))


```
#### 분석결과

Random Forest 모델은 숫자 "1"을 매우 97.38 정확도로 분류할 수 있었으며, 이는 이 모델이 특정 숫자를 매우 잘 분류할 수 있음을 나타냅니다. 반면, 숫자 "9"는 83.34 의 정확도로 다른 숫자와 혼동되는 경향이 있어 분류가 더 어려웠습니다. 

</br>
#### H. 실제 값은 7지만 Random forest model에 의해 1로 예측되는 test data를 찾아 이미지를 몇 개 출력해보자. 눈으로 확인했을 때 7와 1의 구별이 어려운가? 



```{r warning = FALSE, message = FALSE}

# 잘못 분류된 데이터 찾기
misclassified_indices <- which(test_y == 7 & rf_pred == 1)

# 잘못 분류된 데이터 중 일부를 선택하여 시각화
num_images_to_plot <- min(length(misclassified_indices), 4)  # 최대 4개의 이미지를 시각화
par(mfrow = c(2, 2))  # 2x2 그래프 레이아웃 설정

for (i in 1:num_images_to_plot) {
  index <- misclassified_indices[i]
  image_matrix <- matrix(as.numeric(test_x[index, ]), nrow = 28, ncol = 28, byrow = TRUE)
  image(1:28, 1:28, t(apply(image_matrix, 2, rev)), col = gray(seq(0, 1, length = 256)), xlab = "", ylab = "")
  title(main = paste("Index:", index))
}
```



#### 분석 결과

흐릿하게 보여서 구분이 되지 않는다.  